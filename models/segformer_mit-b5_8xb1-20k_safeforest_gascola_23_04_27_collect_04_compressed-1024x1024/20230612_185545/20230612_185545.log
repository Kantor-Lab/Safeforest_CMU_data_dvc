2023/06/12 18:55:46 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 1257820462
    GPU 0: GRID A100X-40C
    CUDA_HOME: None
    GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0
    PyTorch: 2.0.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.15.2
    OpenCV: 4.7.0
    MMEngine: 0.7.4

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1257820462
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2023/06/12 18:55:48 - mmengine - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
data_preprocessor = dict(
    type='SegDataPreProcessor',
    mean=[71.02322328426814, 70.6379940200364, 71.67889280630872],
    std=[33.02850636286781, 32.481152762876164, 33.01011404576837],
    bgr_to_rgb=True,
    pad_val=0,
    seg_pad_val=255,
    size=(1024, 1024))
model = dict(
    type='EncoderDecoder',
    data_preprocessor=dict(
        type='SegDataPreProcessor',
        mean=[71.02322328426814, 70.6379940200364, 71.67889280630872],
        std=[33.02850636286781, 32.481152762876164, 33.01011404576837],
        bgr_to_rgb=True,
        pad_val=0,
        seg_pad_val=255,
        size=(1024, 1024)),
    pretrained=None,
    backbone=dict(
        type='MixVisionTransformer',
        in_channels=3,
        embed_dims=64,
        num_stages=4,
        num_layers=[3, 6, 40, 3],
        num_heads=[1, 2, 5, 8],
        patch_sizes=[7, 3, 3, 3],
        sr_ratios=[8, 4, 2, 1],
        out_indices=(0, 1, 2, 3),
        mlp_ratio=4,
        qkv_bias=True,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.1,
        init_cfg=dict(type='Pretrained', checkpoint='pretrain/mit_b5.pth')),
    decode_head=dict(
        type='SegformerHead',
        in_channels=[64, 128, 320, 512],
        in_index=[0, 1, 2, 3],
        channels=256,
        dropout_ratio=0.1,
        num_classes=4,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(
        mode='slide',
        crop_size=(1024, 1024),
        stride=(768, 768),
        decode_head=dict(
            loss_decode=dict(
                type='CrossEntropyLoss',
                use_sigmoid=False,
                loss_weight=1.0,
                class_weight=[0.86219635, 0.83243454, 0.83369801, 0.99414109
                              ]))))
dataset_type = 'Safeforest23CompressedDataset'
data_root = '/ofo-share/repos-david/Safeforest_CMU_data_dvc//data/site_Gascola/04_27_23/collect_04/processed_01/annotations/safeforest23_condensed'
crop_size = (1024, 1024)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='RandomResize',
        scale=(2048, 1024),
        ratio_range=(0.5, 2.0),
        keep_ratio=True),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs')
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='Resize', scale=(2048, 1024), keep_ratio=True),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs')
]
img_ratios = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]
tta_pipeline = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(
        type='TestTimeAug',
        transforms=[[{
            'type': 'Resize',
            'scale_factor': 0.5,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 0.75,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.0,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.25,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.5,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.75,
            'keep_ratio': True
        }],
                    [{
                        'type': 'RandomFlip',
                        'prob': 0.0,
                        'direction': 'horizontal'
                    }, {
                        'type': 'RandomFlip',
                        'prob': 1.0,
                        'direction': 'horizontal'
                    }], [{
                        'type': 'LoadAnnotations'
                    }], [{
                        'type': 'PackSegInputs'
                    }]])
]
train_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='InfiniteSampler', shuffle=True),
    dataset=dict(
        type='Safeforest23CompressedDataset',
        data_root=
        '/ofo-share/repos-david/Safeforest_CMU_data_dvc//data/site_Gascola/04_27_23/collect_04/processed_01/annotations/safeforest23_condensed',
        data_prefix=dict(
            img_path='img_dir/train', seg_map_path='ann_dir/train'),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='RandomResize',
                scale=(2048, 1024),
                ratio_range=(0.5, 2.0),
                keep_ratio=True),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs')
        ]))
val_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='Safeforest23CompressedDataset',
        data_root=
        '/ofo-share/repos-david/Safeforest_CMU_data_dvc//data/site_Gascola/04_27_23/collect_04/processed_01/annotations/safeforest23_condensed',
        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', scale=(2048, 1024), keep_ratio=True),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs')
        ]))
test_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='Safeforest23CompressedDataset',
        data_root=
        '/ofo-share/repos-david/Safeforest_CMU_data_dvc//data/site_Gascola/04_27_23/collect_04/processed_01/annotations/safeforest23_condensed',
        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', scale=(2048, 1024), keep_ratio=True),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs')
        ]))
val_evaluator = dict(
    type='IoUMetric', iou_metrics=['mIoU', 'mDice', 'mFscore'])
test_evaluator = dict(
    type='IoUMetric', iou_metrics=['mIoU', 'mDice', 'mFscore'])
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'))
vis_backends = [
    dict(type='LocalVisBackend'),
    dict(
        type='WandbVisBackend',
        init_kwargs=dict(
            entity='safeforest-cmu',
            project='mmsegmentation_gascola',
            name=
            'segformer_mit-b0_8xb1-160k_safeforest_gascola_23_04_27_collect_04'
        ))
]
visualizer = dict(
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
        dict(
            type='WandbVisBackend',
            init_kwargs=dict(
                entity='safeforest-cmu',
                project='mmsegmentation_gascola',
                name=
                'segformer_mit-b0_8xb1-160k_safeforest_gascola_23_04_27_collect_04'
            ))
    ],
    name='visualizer')
log_processor = dict(by_epoch=False)
log_level = 'INFO'
load_from = None
resume = False
tta_model = dict(type='SegTTAModel')
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(
        type='AdamW', lr=6e-05, betas=(0.9, 0.999), weight_decay=0.01),
    paramwise_cfg=dict(
        custom_keys=dict(
            pos_block=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
param_scheduler = [
    dict(
        type='LinearLR', start_factor=1e-06, by_epoch=False, begin=0,
        end=1500),
    dict(
        type='PolyLR',
        eta_min=0.0,
        power=1.0,
        begin=1500,
        end=20000,
        by_epoch=False)
]
train_cfg = dict(type='IterBasedTrainLoop', max_iters=20000, val_interval=2000)
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(type='CheckpointHook', by_epoch=False, interval=2000),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(type='SegVisualizationHook'))
launcher = 'none'
work_dir = './work_dirs/segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024'

2023/06/12 18:55:59 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2023/06/12 18:55:59 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train:
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.0.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.0.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.0.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.0.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.0.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.0.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.0.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.1.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.0.1.2.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.0.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.0.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.0.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.0.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.0.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.0.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.0.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.1.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.2.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.3.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.4.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.1.1.5.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.0.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.0.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.0.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.0.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.0.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.0.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.0.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.1.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.2.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.3.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.4.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.5.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.6.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.7.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.8.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.9.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.10.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.11.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.12.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.13.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.14.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.15.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.16.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.17.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.18.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.19.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.20.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.21.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.22.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.23.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.24.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.25.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.26.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.27.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.28.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.29.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.30.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.31.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.32.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.33.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.34.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.35.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.36.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.37.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.38.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.2.1.39.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.0.norm.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.0.norm.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.0.norm.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.0.norm.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.0.norm.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.0.norm.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.0.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.1.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm1.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm1.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm1.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm1.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm1.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm1.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm2.weight:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm2.weight:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm2.weight:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm2.bias:lr=6e-05
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm2.bias:weight_decay=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- backbone.layers.3.1.2.norm2.bias:decay_mult=0.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.conv_seg.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.conv_seg.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.conv_seg.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.conv_seg.bias:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.conv_seg.bias:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.conv_seg.bias:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.0.conv.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.0.conv.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.0.conv.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.0.bn.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.0.bn.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.0.bn.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.0.bn.bias:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.0.bn.bias:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.0.bn.bias:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.1.conv.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.1.conv.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.1.conv.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.1.bn.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.1.bn.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.1.bn.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.1.bn.bias:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.1.bn.bias:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.1.bn.bias:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.2.conv.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.2.conv.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.2.conv.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.2.bn.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.2.bn.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.2.bn.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.2.bn.bias:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.2.bn.bias:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.2.bn.bias:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.3.conv.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.3.conv.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.3.conv.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.3.bn.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.3.bn.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.3.bn.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.3.bn.bias:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.3.bn.bias:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.convs.3.bn.bias:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.fusion_conv.conv.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.fusion_conv.conv.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.fusion_conv.conv.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.fusion_conv.bn.weight:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.fusion_conv.bn.weight:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.fusion_conv.bn.weight:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.fusion_conv.bn.bias:lr=0.0006000000000000001
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.fusion_conv.bn.bias:weight_decay=0.01
2023/06/12 18:56:01 - mmengine - INFO - paramwise_options -- decode_head.fusion_conv.bn.bias:lr_mult=10.0
2023/06/12 18:56:01 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
2023/06/12 18:56:05 - mmengine - INFO - load model from: pretrain/mit_b5.pth
2023/06/12 18:56:05 - mmengine - INFO - Loads checkpoint by local backend from path: pretrain/mit_b5.pth
2023/06/12 18:56:06 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.convs.0.conv.weight, decode_head.convs.0.bn.weight, decode_head.convs.0.bn.bias, decode_head.convs.0.bn.running_mean, decode_head.convs.0.bn.running_var, decode_head.convs.0.bn.num_batches_tracked, decode_head.convs.1.conv.weight, decode_head.convs.1.bn.weight, decode_head.convs.1.bn.bias, decode_head.convs.1.bn.running_mean, decode_head.convs.1.bn.running_var, decode_head.convs.1.bn.num_batches_tracked, decode_head.convs.2.conv.weight, decode_head.convs.2.bn.weight, decode_head.convs.2.bn.bias, decode_head.convs.2.bn.running_mean, decode_head.convs.2.bn.running_var, decode_head.convs.2.bn.num_batches_tracked, decode_head.convs.3.conv.weight, decode_head.convs.3.bn.weight, decode_head.convs.3.bn.bias, decode_head.convs.3.bn.running_mean, decode_head.convs.3.bn.running_var, decode_head.convs.3.bn.num_batches_tracked, decode_head.fusion_conv.conv.weight, decode_head.fusion_conv.bn.weight, decode_head.fusion_conv.bn.bias, decode_head.fusion_conv.bn.running_mean, decode_head.fusion_conv.bn.running_var, decode_head.fusion_conv.bn.num_batches_tracked

Name of parameter - Initialization information

backbone.layers.0.0.projection.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.0.projection.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.0.norm.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.0.norm.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.attn.attn.in_proj_weight - torch.Size([192, 64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.attn.attn.in_proj_bias - torch.Size([192]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.attn.attn.out_proj.weight - torch.Size([64, 64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.attn.attn.out_proj.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.attn.sr.weight - torch.Size([64, 64, 8, 8]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.attn.sr.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.attn.norm.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.attn.norm.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.norm2.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.norm2.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.ffn.layers.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.ffn.layers.0.bias - torch.Size([256]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.ffn.layers.1.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.ffn.layers.1.bias - torch.Size([256]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.ffn.layers.4.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.0.ffn.layers.4.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.attn.attn.in_proj_weight - torch.Size([192, 64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.attn.attn.in_proj_bias - torch.Size([192]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.attn.attn.out_proj.weight - torch.Size([64, 64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.attn.attn.out_proj.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.attn.sr.weight - torch.Size([64, 64, 8, 8]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.attn.sr.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.attn.norm.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.attn.norm.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.norm2.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.norm2.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.ffn.layers.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.ffn.layers.0.bias - torch.Size([256]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.ffn.layers.1.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.ffn.layers.1.bias - torch.Size([256]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.ffn.layers.4.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.1.ffn.layers.4.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.norm1.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.norm1.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.attn.attn.in_proj_weight - torch.Size([192, 64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.attn.attn.in_proj_bias - torch.Size([192]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.attn.attn.out_proj.weight - torch.Size([64, 64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.attn.attn.out_proj.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.attn.sr.weight - torch.Size([64, 64, 8, 8]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.attn.sr.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.attn.norm.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.attn.norm.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.norm2.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.norm2.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.ffn.layers.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.ffn.layers.0.bias - torch.Size([256]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.ffn.layers.1.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.ffn.layers.1.bias - torch.Size([256]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.ffn.layers.4.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.1.2.ffn.layers.4.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.2.weight - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.0.2.bias - torch.Size([64]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.0.projection.weight - torch.Size([128, 64, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.0.projection.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.0.norm.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.0.norm.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.attn.attn.in_proj_weight - torch.Size([384, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.attn.attn.in_proj_bias - torch.Size([384]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.attn.attn.out_proj.weight - torch.Size([128, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.attn.attn.out_proj.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.attn.sr.weight - torch.Size([128, 128, 4, 4]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.attn.sr.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.attn.norm.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.attn.norm.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.ffn.layers.0.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.ffn.layers.1.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.0.ffn.layers.4.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.attn.attn.in_proj_weight - torch.Size([384, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.attn.attn.in_proj_bias - torch.Size([384]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.attn.attn.out_proj.weight - torch.Size([128, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.attn.attn.out_proj.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.attn.sr.weight - torch.Size([128, 128, 4, 4]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.attn.sr.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.attn.norm.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.attn.norm.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.ffn.layers.0.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.ffn.layers.1.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.1.ffn.layers.4.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.attn.attn.in_proj_weight - torch.Size([384, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.attn.attn.in_proj_bias - torch.Size([384]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.attn.attn.out_proj.weight - torch.Size([128, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.attn.attn.out_proj.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.attn.sr.weight - torch.Size([128, 128, 4, 4]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.attn.sr.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.attn.norm.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.attn.norm.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.ffn.layers.0.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.ffn.layers.1.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.2.ffn.layers.4.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.attn.attn.in_proj_weight - torch.Size([384, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.attn.attn.in_proj_bias - torch.Size([384]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.attn.attn.out_proj.weight - torch.Size([128, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.attn.attn.out_proj.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.attn.sr.weight - torch.Size([128, 128, 4, 4]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.attn.sr.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.attn.norm.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.attn.norm.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.ffn.layers.0.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.ffn.layers.1.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.3.ffn.layers.4.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.attn.attn.in_proj_weight - torch.Size([384, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.attn.attn.in_proj_bias - torch.Size([384]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.attn.attn.out_proj.weight - torch.Size([128, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.attn.attn.out_proj.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.attn.sr.weight - torch.Size([128, 128, 4, 4]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.attn.sr.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.attn.norm.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.attn.norm.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.ffn.layers.0.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.ffn.layers.1.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.4.ffn.layers.4.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.norm1.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.norm1.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.attn.attn.in_proj_weight - torch.Size([384, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.attn.attn.in_proj_bias - torch.Size([384]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.attn.attn.out_proj.weight - torch.Size([128, 128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.attn.attn.out_proj.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.attn.sr.weight - torch.Size([128, 128, 4, 4]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.attn.sr.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.attn.norm.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.attn.norm.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.norm2.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.norm2.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.ffn.layers.0.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.ffn.layers.1.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.1.5.ffn.layers.4.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.2.weight - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.1.2.bias - torch.Size([128]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.0.projection.weight - torch.Size([320, 128, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.0.projection.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.0.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.0.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.0.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.1.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.2.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.3.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.4.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.5.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.6.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.7.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.8.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.9.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.10.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.11.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.12.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.13.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.14.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.15.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.16.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.17.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.18.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.19.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.20.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.21.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.22.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.23.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.24.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.25.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.26.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.27.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.28.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.29.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.30.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.31.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.32.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.33.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.34.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.35.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.36.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.37.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.38.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.norm1.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.norm1.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.attn.attn.in_proj_weight - torch.Size([960, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.attn.attn.in_proj_bias - torch.Size([960]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.attn.attn.out_proj.weight - torch.Size([320, 320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.attn.attn.out_proj.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.attn.sr.weight - torch.Size([320, 320, 2, 2]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.attn.sr.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.attn.norm.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.attn.norm.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.norm2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.norm2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.ffn.layers.0.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.ffn.layers.1.bias - torch.Size([1280]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.1.39.ffn.layers.4.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.2.weight - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.2.2.bias - torch.Size([320]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.0.projection.weight - torch.Size([512, 320, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.0.projection.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.0.norm.weight - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.0.norm.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.norm1.weight - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.norm1.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.attn.attn.in_proj_weight - torch.Size([1536, 512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.attn.attn.in_proj_bias - torch.Size([1536]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.attn.attn.out_proj.weight - torch.Size([512, 512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.attn.attn.out_proj.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.norm2.weight - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.norm2.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.ffn.layers.0.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.ffn.layers.0.bias - torch.Size([2048]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.ffn.layers.1.weight - torch.Size([2048, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.ffn.layers.1.bias - torch.Size([2048]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.ffn.layers.4.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.0.ffn.layers.4.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.norm1.weight - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.norm1.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.attn.attn.in_proj_weight - torch.Size([1536, 512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.attn.attn.in_proj_bias - torch.Size([1536]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.attn.attn.out_proj.weight - torch.Size([512, 512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.attn.attn.out_proj.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.norm2.weight - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.norm2.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.ffn.layers.0.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.ffn.layers.0.bias - torch.Size([2048]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.ffn.layers.1.weight - torch.Size([2048, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.ffn.layers.1.bias - torch.Size([2048]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.ffn.layers.4.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.1.ffn.layers.4.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.norm1.weight - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.norm1.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.attn.attn.in_proj_weight - torch.Size([1536, 512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.attn.attn.in_proj_bias - torch.Size([1536]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.attn.attn.out_proj.weight - torch.Size([512, 512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.attn.attn.out_proj.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.norm2.weight - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.norm2.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.ffn.layers.0.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.ffn.layers.0.bias - torch.Size([2048]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.ffn.layers.1.weight - torch.Size([2048, 1, 3, 3]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.ffn.layers.1.bias - torch.Size([2048]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.ffn.layers.4.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.1.2.ffn.layers.4.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.2.weight - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

backbone.layers.3.2.bias - torch.Size([512]): 
PretrainedInit: load from pretrain/mit_b5.pth 

decode_head.conv_seg.weight - torch.Size([4, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.conv.weight - torch.Size([256, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.2.conv.weight - torch.Size([256, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.3.conv.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fusion_conv.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.fusion_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fusion_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023/06/12 18:56:07 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2023/06/12 18:56:07 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2023/06/12 18:56:07 - mmengine - INFO - Checkpoints will be saved to /ofo-share/repos-david/mmsegmentation_v2/work_dirs/segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024.
2023/06/12 18:56:55 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 18:56:55 - mmengine - INFO - Iter(train) [   35/20000]  lr: 1.3610e-06  eta: 7:43:02  time: 0.8907  data_time: 0.0161  memory: 24054  loss: 0.1339  decode.loss_ce: 0.1339  decode.acc_seg: 43.2516
2023/06/12 18:57:09 - mmengine - INFO - Iter(train) [   50/20000]  lr: 1.9614e-06  eta: 6:53:07  time: 0.8913  data_time: 0.0179  memory: 12683  loss: 0.1429  decode.loss_ce: 0.1429  decode.acc_seg: 22.8743
2023/06/12 18:57:53 - mmengine - INFO - Iter(train) [  100/20000]  lr: 3.9627e-06  eta: 5:54:05  time: 0.8873  data_time: 0.0170  memory: 12683  loss: 0.1237  decode.loss_ce: 0.1237  decode.acc_seg: 46.8327
2023/06/12 18:58:38 - mmengine - INFO - Iter(train) [  150/20000]  lr: 5.9640e-06  eta: 5:34:03  time: 0.8897  data_time: 0.0160  memory: 12683  loss: 0.1150  decode.loss_ce: 0.1150  decode.acc_seg: 97.7762
2023/06/12 18:59:23 - mmengine - INFO - Iter(train) [  200/20000]  lr: 7.9654e-06  eta: 5:23:22  time: 0.8934  data_time: 0.0165  memory: 12683  loss: 0.0448  decode.loss_ce: 0.0448  decode.acc_seg: 95.5084
2023/06/12 19:00:08 - mmengine - INFO - Iter(train) [  250/20000]  lr: 9.9667e-06  eta: 5:17:47  time: 0.9315  data_time: 0.0170  memory: 12683  loss: 0.0809  decode.loss_ce: 0.0809  decode.acc_seg: 74.0951
2023/06/12 19:00:58 - mmengine - INFO - Iter(train) [  300/20000]  lr: 1.1968e-05  eta: 5:18:36  time: 1.2362  data_time: 0.0169  memory: 12683  loss: 0.0491  decode.loss_ce: 0.0491  decode.acc_seg: 100.0000
2023/06/12 19:01:58 - mmengine - INFO - Iter(train) [  350/20000]  lr: 1.3969e-05  eta: 5:28:34  time: 0.8882  data_time: 0.0165  memory: 12683  loss: 0.0479  decode.loss_ce: 0.0479  decode.acc_seg: 93.9573
2023/06/12 19:02:42 - mmengine - INFO - Iter(train) [  400/20000]  lr: 1.5971e-05  eta: 5:23:09  time: 0.8910  data_time: 0.0146  memory: 12683  loss: 0.0297  decode.loss_ce: 0.0297  decode.acc_seg: 98.7046
2023/06/12 19:03:29 - mmengine - INFO - Iter(train) [  450/20000]  lr: 1.7972e-05  eta: 5:20:26  time: 0.8955  data_time: 0.0153  memory: 12683  loss: 0.0425  decode.loss_ce: 0.0425  decode.acc_seg: 100.0000
2023/06/12 19:04:14 - mmengine - INFO - Iter(train) [  500/20000]  lr: 1.9973e-05  eta: 5:16:47  time: 0.9003  data_time: 0.0131  memory: 12683  loss: 0.0400  decode.loss_ce: 0.0400  decode.acc_seg: 88.5169
2023/06/12 19:04:59 - mmengine - INFO - Iter(train) [  550/20000]  lr: 2.1975e-05  eta: 5:13:46  time: 0.9072  data_time: 0.0142  memory: 12683  loss: 0.0421  decode.loss_ce: 0.0421  decode.acc_seg: 95.9456
2023/06/12 19:05:44 - mmengine - INFO - Iter(train) [  600/20000]  lr: 2.3976e-05  eta: 5:11:05  time: 0.8973  data_time: 0.0152  memory: 12683  loss: 0.0152  decode.loss_ce: 0.0152  decode.acc_seg: 92.4749
2023/06/12 19:06:29 - mmengine - INFO - Iter(train) [  650/20000]  lr: 2.5977e-05  eta: 5:08:44  time: 0.9014  data_time: 0.0147  memory: 12683  loss: 0.0223  decode.loss_ce: 0.0223  decode.acc_seg: 93.5166
2023/06/12 19:07:14 - mmengine - INFO - Iter(train) [  700/20000]  lr: 2.7979e-05  eta: 5:06:35  time: 0.8984  data_time: 0.0162  memory: 12683  loss: 0.0369  decode.loss_ce: 0.0369  decode.acc_seg: 71.8465
2023/06/12 19:07:59 - mmengine - INFO - Iter(train) [  750/20000]  lr: 2.9980e-05  eta: 5:04:40  time: 0.9015  data_time: 0.0163  memory: 12683  loss: 0.0139  decode.loss_ce: 0.0139  decode.acc_seg: 88.2360
2023/06/12 19:08:44 - mmengine - INFO - Iter(train) [  800/20000]  lr: 3.1981e-05  eta: 5:02:48  time: 0.8940  data_time: 0.0164  memory: 12683  loss: 0.0744  decode.loss_ce: 0.0744  decode.acc_seg: 92.6428
2023/06/12 19:09:29 - mmengine - INFO - Iter(train) [  850/20000]  lr: 3.3983e-05  eta: 5:01:06  time: 0.8963  data_time: 0.0139  memory: 12683  loss: 0.0197  decode.loss_ce: 0.0197  decode.acc_seg: 98.1215
2023/06/12 19:10:14 - mmengine - INFO - Iter(train) [  900/20000]  lr: 3.5984e-05  eta: 4:59:35  time: 0.9077  data_time: 0.0176  memory: 12683  loss: 0.0318  decode.loss_ce: 0.0318  decode.acc_seg: 91.0045
2023/06/12 19:10:59 - mmengine - INFO - Iter(train) [  950/20000]  lr: 3.7985e-05  eta: 4:58:05  time: 0.9017  data_time: 0.0164  memory: 12683  loss: 0.0067  decode.loss_ce: 0.0067  decode.acc_seg: 98.5687
2023/06/12 19:11:44 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 19:11:44 - mmengine - INFO - Iter(train) [ 1000/20000]  lr: 3.9987e-05  eta: 4:56:42  time: 0.9015  data_time: 0.0160  memory: 12683  loss: 0.0209  decode.loss_ce: 0.0209  decode.acc_seg: 92.7489
2023/06/12 19:12:28 - mmengine - INFO - Iter(train) [ 1050/20000]  lr: 4.1988e-05  eta: 4:55:20  time: 0.8998  data_time: 0.0165  memory: 12683  loss: 0.0158  decode.loss_ce: 0.0158  decode.acc_seg: 97.0789
2023/06/12 19:13:13 - mmengine - INFO - Iter(train) [ 1100/20000]  lr: 4.3989e-05  eta: 4:53:47  time: 0.8115  data_time: 0.0150  memory: 12683  loss: 0.0161  decode.loss_ce: 0.0161  decode.acc_seg: 94.0337
2023/06/12 19:13:37 - mmengine - INFO - Iter(train) [ 1150/20000]  lr: 4.5991e-05  eta: 4:47:01  time: 0.4904  data_time: 0.0124  memory: 12683  loss: 0.0181  decode.loss_ce: 0.0181  decode.acc_seg: 92.6865
2023/06/12 19:14:02 - mmengine - INFO - Iter(train) [ 1200/20000]  lr: 4.7992e-05  eta: 4:40:44  time: 0.4902  data_time: 0.0124  memory: 12683  loss: 0.0245  decode.loss_ce: 0.0245  decode.acc_seg: 98.3264
2023/06/12 19:14:26 - mmengine - INFO - Iter(train) [ 1250/20000]  lr: 4.9993e-05  eta: 4:34:54  time: 0.4878  data_time: 0.0139  memory: 12683  loss: 0.0258  decode.loss_ce: 0.0258  decode.acc_seg: 98.1168
2023/06/12 19:14:51 - mmengine - INFO - Iter(train) [ 1300/20000]  lr: 5.1995e-05  eta: 4:29:29  time: 0.4880  data_time: 0.0121  memory: 12683  loss: 0.0106  decode.loss_ce: 0.0106  decode.acc_seg: 98.3637
2023/06/12 19:15:15 - mmengine - INFO - Iter(train) [ 1350/20000]  lr: 5.3996e-05  eta: 4:24:24  time: 0.4909  data_time: 0.0130  memory: 12683  loss: 0.0076  decode.loss_ce: 0.0076  decode.acc_seg: 97.9553
2023/06/12 19:15:39 - mmengine - INFO - Iter(train) [ 1400/20000]  lr: 5.5997e-05  eta: 4:19:41  time: 0.4897  data_time: 0.0125  memory: 12683  loss: 0.0379  decode.loss_ce: 0.0379  decode.acc_seg: 98.2655
2023/06/12 19:16:04 - mmengine - INFO - Iter(train) [ 1450/20000]  lr: 5.7999e-05  eta: 4:15:17  time: 0.4887  data_time: 0.0120  memory: 12683  loss: 0.0114  decode.loss_ce: 0.0114  decode.acc_seg: 100.0000
2023/06/12 19:16:28 - mmengine - INFO - Iter(train) [ 1500/20000]  lr: 6.0000e-05  eta: 4:11:08  time: 0.4884  data_time: 0.0118  memory: 12683  loss: 0.0071  decode.loss_ce: 0.0071  decode.acc_seg: 98.0114
2023/06/12 19:16:53 - mmengine - INFO - Iter(train) [ 1550/20000]  lr: 5.9841e-05  eta: 4:07:16  time: 0.4905  data_time: 0.0127  memory: 12683  loss: 0.0182  decode.loss_ce: 0.0182  decode.acc_seg: 86.3767
2023/06/12 19:17:18 - mmengine - INFO - Iter(train) [ 1600/20000]  lr: 5.9679e-05  eta: 4:03:35  time: 0.4897  data_time: 0.0126  memory: 12683  loss: 0.0199  decode.loss_ce: 0.0199  decode.acc_seg: 99.2450
2023/06/12 19:17:42 - mmengine - INFO - Iter(train) [ 1650/20000]  lr: 5.9517e-05  eta: 4:00:09  time: 0.4904  data_time: 0.0129  memory: 12683  loss: 0.0097  decode.loss_ce: 0.0097  decode.acc_seg: 96.2505
2023/06/12 19:18:07 - mmengine - INFO - Iter(train) [ 1700/20000]  lr: 5.9355e-05  eta: 3:56:51  time: 0.4896  data_time: 0.0122  memory: 12683  loss: 0.0318  decode.loss_ce: 0.0318  decode.acc_seg: 99.5170
2023/06/12 19:18:31 - mmengine - INFO - Iter(train) [ 1750/20000]  lr: 5.9192e-05  eta: 3:53:43  time: 0.4913  data_time: 0.0147  memory: 12683  loss: 0.0371  decode.loss_ce: 0.0371  decode.acc_seg: 90.0330
2023/06/12 19:18:56 - mmengine - INFO - Iter(train) [ 1800/20000]  lr: 5.9030e-05  eta: 3:50:44  time: 0.4903  data_time: 0.0126  memory: 12683  loss: 0.0125  decode.loss_ce: 0.0125  decode.acc_seg: 98.1308
2023/06/12 19:19:20 - mmengine - INFO - Iter(train) [ 1850/20000]  lr: 5.8868e-05  eta: 3:47:54  time: 0.4908  data_time: 0.0144  memory: 12683  loss: 0.0280  decode.loss_ce: 0.0280  decode.acc_seg: 74.2525
2023/06/12 19:19:45 - mmengine - INFO - Iter(train) [ 1900/20000]  lr: 5.8706e-05  eta: 3:45:12  time: 0.4936  data_time: 0.0158  memory: 12683  loss: 0.0742  decode.loss_ce: 0.0742  decode.acc_seg: 97.9236
2023/06/12 19:20:10 - mmengine - INFO - Iter(train) [ 1950/20000]  lr: 5.8544e-05  eta: 3:42:37  time: 0.4906  data_time: 0.0138  memory: 12683  loss: 0.0122  decode.loss_ce: 0.0122  decode.acc_seg: 99.0871
2023/06/12 19:20:34 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 19:20:34 - mmengine - INFO - Iter(train) [ 2000/20000]  lr: 5.8382e-05  eta: 3:40:08  time: 0.4890  data_time: 0.0136  memory: 12683  loss: 0.0140  decode.loss_ce: 0.0140  decode.acc_seg: 98.0798
2023/06/12 19:20:34 - mmengine - INFO - Saving checkpoint at 2000 iterations
2023/06/12 19:20:45 - mmengine - INFO - per class results:
2023/06/12 19:20:45 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
|    Fuel    | 78.86 | 86.67 | 88.18 | 88.18  |   89.74   | 86.67  |
|   Canopy   | 95.48 | 96.62 | 97.69 | 97.69  |   98.79   | 96.62  |
| Background |  85.5 | 95.02 | 92.19 | 92.19  |   89.52   | 95.02  |
|   Trunks   |  nan  |  nan  |  nan  |  nan   |    nan    |  nan   |
+------------+-------+-------+-------+--------+-----------+--------+
2023/06/12 19:20:45 - mmengine - INFO - Iter(val) [6/6]    aAcc: 93.3300  mIoU: 86.6100  mAcc: 92.7700  mDice: 92.6800  mFscore: 92.6800  mPrecision: 92.6800  mRecall: 92.7700  data_time: 0.4856  time: 0.6752
2023/06/12 19:21:09 - mmengine - INFO - Iter(train) [ 2050/20000]  lr: 5.8219e-05  eta: 3:37:45  time: 0.4892  data_time: 0.0127  memory: 12683  loss: 0.0368  decode.loss_ce: 0.0368  decode.acc_seg: 99.4277
2023/06/12 19:21:34 - mmengine - INFO - Iter(train) [ 2100/20000]  lr: 5.8057e-05  eta: 3:35:27  time: 0.4937  data_time: 0.0135  memory: 12683  loss: 0.0117  decode.loss_ce: 0.0117  decode.acc_seg: 99.1422
2023/06/12 19:21:58 - mmengine - INFO - Iter(train) [ 2150/20000]  lr: 5.7895e-05  eta: 3:33:14  time: 0.4912  data_time: 0.0132  memory: 12683  loss: 0.0140  decode.loss_ce: 0.0140  decode.acc_seg: 100.0000
2023/06/12 19:22:23 - mmengine - INFO - Iter(train) [ 2200/20000]  lr: 5.7733e-05  eta: 3:31:06  time: 0.4898  data_time: 0.0126  memory: 12683  loss: 0.0143  decode.loss_ce: 0.0143  decode.acc_seg: 99.3485
2023/06/12 19:22:47 - mmengine - INFO - Iter(train) [ 2250/20000]  lr: 5.7571e-05  eta: 3:29:04  time: 0.4915  data_time: 0.0133  memory: 12683  loss: 0.0162  decode.loss_ce: 0.0162  decode.acc_seg: 91.7183
2023/06/12 19:23:12 - mmengine - INFO - Iter(train) [ 2300/20000]  lr: 5.7409e-05  eta: 3:27:06  time: 0.4881  data_time: 0.0128  memory: 12683  loss: 0.0092  decode.loss_ce: 0.0092  decode.acc_seg: 100.0000
2023/06/12 19:23:36 - mmengine - INFO - Iter(train) [ 2350/20000]  lr: 5.7246e-05  eta: 3:25:11  time: 0.4858  data_time: 0.0129  memory: 12683  loss: 0.0113  decode.loss_ce: 0.0113  decode.acc_seg: 99.8853
2023/06/12 19:24:01 - mmengine - INFO - Iter(train) [ 2400/20000]  lr: 5.7084e-05  eta: 3:23:20  time: 0.4893  data_time: 0.0125  memory: 12683  loss: 0.0092  decode.loss_ce: 0.0092  decode.acc_seg: 39.3533
2023/06/12 19:24:25 - mmengine - INFO - Iter(train) [ 2450/20000]  lr: 5.6922e-05  eta: 3:21:33  time: 0.4899  data_time: 0.0131  memory: 12683  loss: 0.0311  decode.loss_ce: 0.0311  decode.acc_seg: 96.9085
2023/06/12 19:24:50 - mmengine - INFO - Iter(train) [ 2500/20000]  lr: 5.6760e-05  eta: 3:19:51  time: 0.4889  data_time: 0.0123  memory: 12683  loss: 0.0065  decode.loss_ce: 0.0065  decode.acc_seg: 99.0787
2023/06/12 19:25:15 - mmengine - INFO - Iter(train) [ 2550/20000]  lr: 5.6598e-05  eta: 3:18:11  time: 0.4917  data_time: 0.0140  memory: 12683  loss: 0.0048  decode.loss_ce: 0.0048  decode.acc_seg: 97.6827
2023/06/12 19:25:39 - mmengine - INFO - Iter(train) [ 2600/20000]  lr: 5.6435e-05  eta: 3:16:33  time: 0.4892  data_time: 0.0124  memory: 12683  loss: 0.0046  decode.loss_ce: 0.0046  decode.acc_seg: 96.2491
2023/06/12 19:26:04 - mmengine - INFO - Iter(train) [ 2650/20000]  lr: 5.6273e-05  eta: 3:14:57  time: 0.4895  data_time: 0.0128  memory: 12683  loss: 0.0085  decode.loss_ce: 0.0085  decode.acc_seg: 100.0000
2023/06/12 19:26:28 - mmengine - INFO - Iter(train) [ 2700/20000]  lr: 5.6111e-05  eta: 3:13:25  time: 0.4885  data_time: 0.0121  memory: 12683  loss: 0.0095  decode.loss_ce: 0.0095  decode.acc_seg: 97.5633
2023/06/12 19:26:53 - mmengine - INFO - Iter(train) [ 2750/20000]  lr: 5.5949e-05  eta: 3:11:54  time: 0.4899  data_time: 0.0129  memory: 12683  loss: 0.0114  decode.loss_ce: 0.0114  decode.acc_seg: 86.0261
2023/06/12 19:27:17 - mmengine - INFO - Iter(train) [ 2800/20000]  lr: 5.5787e-05  eta: 3:10:27  time: 0.4939  data_time: 0.0150  memory: 12683  loss: 0.0072  decode.loss_ce: 0.0072  decode.acc_seg: 81.7684
2023/06/12 19:27:42 - mmengine - INFO - Iter(train) [ 2850/20000]  lr: 5.5625e-05  eta: 3:09:03  time: 0.4890  data_time: 0.0121  memory: 12683  loss: 0.0086  decode.loss_ce: 0.0086  decode.acc_seg: 100.0000
2023/06/12 19:28:06 - mmengine - INFO - Iter(train) [ 2900/20000]  lr: 5.5462e-05  eta: 3:07:39  time: 0.4909  data_time: 0.0134  memory: 12683  loss: 0.0137  decode.loss_ce: 0.0137  decode.acc_seg: 89.6218
2023/06/12 19:28:31 - mmengine - INFO - Iter(train) [ 2950/20000]  lr: 5.5300e-05  eta: 3:06:18  time: 0.4921  data_time: 0.0136  memory: 12683  loss: 0.0176  decode.loss_ce: 0.0176  decode.acc_seg: 98.5630
2023/06/12 19:28:55 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 19:28:55 - mmengine - INFO - Iter(train) [ 3000/20000]  lr: 5.5138e-05  eta: 3:04:56  time: 0.4807  data_time: 0.0141  memory: 12683  loss: 0.0162  decode.loss_ce: 0.0162  decode.acc_seg: 100.0000
2023/06/12 19:29:19 - mmengine - INFO - Iter(train) [ 3050/20000]  lr: 5.4976e-05  eta: 3:03:35  time: 0.4698  data_time: 0.0122  memory: 12683  loss: 0.0080  decode.loss_ce: 0.0080  decode.acc_seg: 92.6427
2023/06/12 19:29:43 - mmengine - INFO - Iter(train) [ 3100/20000]  lr: 5.4814e-05  eta: 3:02:14  time: 0.4741  data_time: 0.0129  memory: 12683  loss: 0.0107  decode.loss_ce: 0.0107  decode.acc_seg: 100.0000
2023/06/12 19:30:06 - mmengine - INFO - Iter(train) [ 3150/20000]  lr: 5.4652e-05  eta: 3:00:54  time: 0.4591  data_time: 0.0087  memory: 12683  loss: 0.0118  decode.loss_ce: 0.0118  decode.acc_seg: 99.3650
2023/06/12 19:30:30 - mmengine - INFO - Iter(train) [ 3200/20000]  lr: 5.4489e-05  eta: 2:59:35  time: 0.4661  data_time: 0.0101  memory: 12683  loss: 0.0074  decode.loss_ce: 0.0074  decode.acc_seg: 98.4694
2023/06/12 19:30:53 - mmengine - INFO - Iter(train) [ 3250/20000]  lr: 5.4327e-05  eta: 2:58:20  time: 0.4695  data_time: 0.0114  memory: 12683  loss: 0.0139  decode.loss_ce: 0.0139  decode.acc_seg: 93.1705
2023/06/12 19:31:17 - mmengine - INFO - Iter(train) [ 3300/20000]  lr: 5.4165e-05  eta: 2:57:05  time: 0.4682  data_time: 0.0115  memory: 12683  loss: 0.0038  decode.loss_ce: 0.0038  decode.acc_seg: 100.0000
2023/06/12 19:31:40 - mmengine - INFO - Iter(train) [ 3350/20000]  lr: 5.4003e-05  eta: 2:55:53  time: 0.4812  data_time: 0.0147  memory: 12683  loss: 0.0357  decode.loss_ce: 0.0357  decode.acc_seg: 99.5112
2023/06/12 19:32:04 - mmengine - INFO - Iter(train) [ 3400/20000]  lr: 5.3841e-05  eta: 2:54:44  time: 0.4845  data_time: 0.0153  memory: 12683  loss: 0.0174  decode.loss_ce: 0.0174  decode.acc_seg: 94.4262
2023/06/12 19:32:29 - mmengine - INFO - Iter(train) [ 3450/20000]  lr: 5.3679e-05  eta: 2:53:37  time: 0.4807  data_time: 0.0142  memory: 12683  loss: 0.0138  decode.loss_ce: 0.0138  decode.acc_seg: 90.7017
2023/06/12 19:32:53 - mmengine - INFO - Iter(train) [ 3500/20000]  lr: 5.3516e-05  eta: 2:52:31  time: 0.4905  data_time: 0.0159  memory: 12683  loss: 0.0166  decode.loss_ce: 0.0166  decode.acc_seg: 92.6218
2023/06/12 19:33:16 - mmengine - INFO - Iter(train) [ 3550/20000]  lr: 5.3354e-05  eta: 2:51:23  time: 0.4687  data_time: 0.0117  memory: 12683  loss: 0.0058  decode.loss_ce: 0.0058  decode.acc_seg: 99.9720
2023/06/12 19:33:40 - mmengine - INFO - Iter(train) [ 3600/20000]  lr: 5.3192e-05  eta: 2:50:16  time: 0.4682  data_time: 0.0117  memory: 12683  loss: 0.0095  decode.loss_ce: 0.0095  decode.acc_seg: 96.2178
2023/06/12 19:34:03 - mmengine - INFO - Iter(train) [ 3650/20000]  lr: 5.3030e-05  eta: 2:49:11  time: 0.4691  data_time: 0.0121  memory: 12683  loss: 0.0049  decode.loss_ce: 0.0049  decode.acc_seg: 99.7334
2023/06/12 19:34:27 - mmengine - INFO - Iter(train) [ 3700/20000]  lr: 5.2868e-05  eta: 2:48:06  time: 0.4679  data_time: 0.0115  memory: 12683  loss: 0.0053  decode.loss_ce: 0.0053  decode.acc_seg: 100.0000
2023/06/12 19:34:50 - mmengine - INFO - Iter(train) [ 3750/20000]  lr: 5.2706e-05  eta: 2:47:03  time: 0.4684  data_time: 0.0119  memory: 12683  loss: 0.0072  decode.loss_ce: 0.0072  decode.acc_seg: 99.3859
2023/06/12 19:35:13 - mmengine - INFO - Iter(train) [ 3800/20000]  lr: 5.2543e-05  eta: 2:46:00  time: 0.4691  data_time: 0.0119  memory: 12683  loss: 0.0060  decode.loss_ce: 0.0060  decode.acc_seg: 76.2945
2023/06/12 19:35:37 - mmengine - INFO - Iter(train) [ 3850/20000]  lr: 5.2381e-05  eta: 2:44:59  time: 0.4677  data_time: 0.0116  memory: 12683  loss: 0.0048  decode.loss_ce: 0.0048  decode.acc_seg: 99.5071
2023/06/12 19:36:00 - mmengine - INFO - Iter(train) [ 3900/20000]  lr: 5.2219e-05  eta: 2:43:59  time: 0.4688  data_time: 0.0118  memory: 12683  loss: 0.0045  decode.loss_ce: 0.0045  decode.acc_seg: 98.9642
2023/06/12 19:36:24 - mmengine - INFO - Iter(train) [ 3950/20000]  lr: 5.2057e-05  eta: 2:42:59  time: 0.4691  data_time: 0.0120  memory: 12683  loss: 0.0088  decode.loss_ce: 0.0088  decode.acc_seg: 78.9754
2023/06/12 19:36:48 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 19:36:48 - mmengine - INFO - Iter(train) [ 4000/20000]  lr: 5.1895e-05  eta: 2:42:02  time: 0.4801  data_time: 0.0150  memory: 12683  loss: 0.0080  decode.loss_ce: 0.0080  decode.acc_seg: 97.9469
2023/06/12 19:36:48 - mmengine - INFO - Saving checkpoint at 4000 iterations
2023/06/12 19:36:55 - mmengine - INFO - per class results:
2023/06/12 19:36:55 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
|    Fuel    | 83.01 | 87.81 | 90.72 | 90.72  |   93.83   | 87.81  |
|   Canopy   | 96.58 | 98.35 | 98.26 | 98.26  |   98.17   | 98.35  |
| Background | 88.32 | 96.46 |  93.8 |  93.8  |   91.28   | 96.46  |
|   Trunks   |  nan  |  nan  |  nan  |  nan   |    nan    |  nan   |
+------------+-------+-------+-------+--------+-----------+--------+
2023/06/12 19:36:55 - mmengine - INFO - Iter(val) [6/6]    aAcc: 94.8000  mIoU: 89.3000  mAcc: 94.2100  mDice: 94.2600  mFscore: 94.2600  mPrecision: 94.4200  mRecall: 94.2100  data_time: 0.1354  time: 0.3187
2023/06/12 19:37:19 - mmengine - INFO - Iter(train) [ 4050/20000]  lr: 5.1733e-05  eta: 2:41:06  time: 0.4704  data_time: 0.0121  memory: 12683  loss: 0.0042  decode.loss_ce: 0.0042  decode.acc_seg: 94.3060
2023/06/12 19:37:42 - mmengine - INFO - Iter(train) [ 4100/20000]  lr: 5.1570e-05  eta: 2:40:09  time: 0.4612  data_time: 0.0100  memory: 12683  loss: 0.0046  decode.loss_ce: 0.0046  decode.acc_seg: 99.9787
2023/06/12 19:38:06 - mmengine - INFO - Iter(train) [ 4150/20000]  lr: 5.1408e-05  eta: 2:39:13  time: 0.4775  data_time: 0.0137  memory: 12683  loss: 0.0066  decode.loss_ce: 0.0066  decode.acc_seg: 98.0616
2023/06/12 19:38:29 - mmengine - INFO - Iter(train) [ 4200/20000]  lr: 5.1246e-05  eta: 2:38:19  time: 0.4744  data_time: 0.0124  memory: 12683  loss: 0.0062  decode.loss_ce: 0.0062  decode.acc_seg: 97.9521
2023/06/12 19:38:53 - mmengine - INFO - Iter(train) [ 4250/20000]  lr: 5.1084e-05  eta: 2:37:26  time: 0.4936  data_time: 0.0151  memory: 12683  loss: 0.0079  decode.loss_ce: 0.0079  decode.acc_seg: 99.9820
2023/06/12 19:39:18 - mmengine - INFO - Iter(train) [ 4300/20000]  lr: 5.0922e-05  eta: 2:36:37  time: 0.4931  data_time: 0.0135  memory: 12683  loss: 0.0068  decode.loss_ce: 0.0068  decode.acc_seg: 82.0739
2023/06/12 19:39:43 - mmengine - INFO - Iter(train) [ 4350/20000]  lr: 5.0760e-05  eta: 2:35:48  time: 0.4957  data_time: 0.0155  memory: 12683  loss: 0.0076  decode.loss_ce: 0.0076  decode.acc_seg: 98.5959
2023/06/12 19:40:07 - mmengine - INFO - Iter(train) [ 4400/20000]  lr: 5.0597e-05  eta: 2:35:00  time: 0.4956  data_time: 0.0160  memory: 12683  loss: 0.0036  decode.loss_ce: 0.0036  decode.acc_seg: 99.7650
2023/06/12 19:40:32 - mmengine - INFO - Iter(train) [ 4450/20000]  lr: 5.0435e-05  eta: 2:34:12  time: 0.4995  data_time: 0.0172  memory: 12683  loss: 0.0039  decode.loss_ce: 0.0039  decode.acc_seg: 98.2679
2023/06/12 19:40:57 - mmengine - INFO - Iter(train) [ 4500/20000]  lr: 5.0273e-05  eta: 2:33:25  time: 0.4916  data_time: 0.0144  memory: 12683  loss: 0.0061  decode.loss_ce: 0.0061  decode.acc_seg: 98.5250
2023/06/12 19:41:21 - mmengine - INFO - Iter(train) [ 4550/20000]  lr: 5.0111e-05  eta: 2:32:38  time: 0.4897  data_time: 0.0134  memory: 12683  loss: 0.0016  decode.loss_ce: 0.0016  decode.acc_seg: 99.1428
2023/06/12 19:41:46 - mmengine - INFO - Iter(train) [ 4600/20000]  lr: 4.9949e-05  eta: 2:31:51  time: 0.4888  data_time: 0.0121  memory: 12683  loss: 0.0021  decode.loss_ce: 0.0021  decode.acc_seg: 99.9728
2023/06/12 19:42:10 - mmengine - INFO - Iter(train) [ 4650/20000]  lr: 4.9786e-05  eta: 2:31:05  time: 0.4881  data_time: 0.0120  memory: 12683  loss: 0.0057  decode.loss_ce: 0.0057  decode.acc_seg: 99.6911
2023/06/12 19:42:35 - mmengine - INFO - Iter(train) [ 4700/20000]  lr: 4.9624e-05  eta: 2:30:19  time: 0.4889  data_time: 0.0124  memory: 12683  loss: 0.0023  decode.loss_ce: 0.0023  decode.acc_seg: 100.0000
2023/06/12 19:43:02 - mmengine - INFO - Iter(train) [ 4750/20000]  lr: 4.9462e-05  eta: 2:29:42  time: 0.7106  data_time: 0.0166  memory: 12683  loss: 0.0039  decode.loss_ce: 0.0039  decode.acc_seg: 99.3356
2023/06/12 19:43:38 - mmengine - INFO - Iter(train) [ 4800/20000]  lr: 4.9300e-05  eta: 2:29:32  time: 0.7045  data_time: 0.0089  memory: 12683  loss: 0.0149  decode.loss_ce: 0.0149  decode.acc_seg: 99.3420
2023/06/12 19:44:14 - mmengine - INFO - Iter(train) [ 4850/20000]  lr: 4.9138e-05  eta: 2:29:25  time: 0.6735  data_time: 0.0113  memory: 12683  loss: 0.0025  decode.loss_ce: 0.0025  decode.acc_seg: 100.0000
2023/06/12 19:44:51 - mmengine - INFO - Iter(train) [ 4900/20000]  lr: 4.8976e-05  eta: 2:29:18  time: 0.6856  data_time: 0.0095  memory: 12683  loss: 0.0050  decode.loss_ce: 0.0050  decode.acc_seg: 97.4914
2023/06/12 19:45:29 - mmengine - INFO - Iter(train) [ 4950/20000]  lr: 4.8813e-05  eta: 2:29:14  time: 0.7621  data_time: 0.0106  memory: 12683  loss: 0.0042  decode.loss_ce: 0.0042  decode.acc_seg: 99.3787
2023/06/12 19:46:07 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 19:46:07 - mmengine - INFO - Iter(train) [ 5000/20000]  lr: 4.8651e-05  eta: 2:29:09  time: 0.8160  data_time: 0.0138  memory: 12683  loss: 0.0024  decode.loss_ce: 0.0024  decode.acc_seg: 99.9778
2023/06/12 19:46:40 - mmengine - INFO - Iter(train) [ 5050/20000]  lr: 4.8489e-05  eta: 2:28:48  time: 0.7881  data_time: 0.0087  memory: 12683  loss: 0.0265  decode.loss_ce: 0.0265  decode.acc_seg: 99.9242
2023/06/12 19:47:17 - mmengine - INFO - Iter(train) [ 5100/20000]  lr: 4.8327e-05  eta: 2:28:38  time: 0.8012  data_time: 0.0103  memory: 12683  loss: 0.0029  decode.loss_ce: 0.0029  decode.acc_seg: 99.9223
2023/06/12 19:47:54 - mmengine - INFO - Iter(train) [ 5150/20000]  lr: 4.8165e-05  eta: 2:28:30  time: 0.7779  data_time: 0.0100  memory: 12683  loss: 0.0041  decode.loss_ce: 0.0041  decode.acc_seg: 98.7667
2023/06/12 19:48:31 - mmengine - INFO - Iter(train) [ 5200/20000]  lr: 4.8003e-05  eta: 2:28:19  time: 0.7904  data_time: 0.0113  memory: 12683  loss: 0.0080  decode.loss_ce: 0.0080  decode.acc_seg: 94.4582
2023/06/12 19:49:08 - mmengine - INFO - Iter(train) [ 5250/20000]  lr: 4.7840e-05  eta: 2:28:09  time: 0.8047  data_time: 0.0119  memory: 12683  loss: 0.0690  decode.loss_ce: 0.0690  decode.acc_seg: 98.1791
2023/06/12 19:49:46 - mmengine - INFO - Iter(train) [ 5300/20000]  lr: 4.7678e-05  eta: 2:27:59  time: 0.8150  data_time: 0.0125  memory: 12683  loss: 0.0063  decode.loss_ce: 0.0063  decode.acc_seg: 99.3856
2023/06/12 19:50:23 - mmengine - INFO - Iter(train) [ 5350/20000]  lr: 4.7516e-05  eta: 2:27:48  time: 0.8057  data_time: 0.0094  memory: 12683  loss: 0.0065  decode.loss_ce: 0.0065  decode.acc_seg: 99.3186
2023/06/12 19:51:00 - mmengine - INFO - Iter(train) [ 5400/20000]  lr: 4.7354e-05  eta: 2:27:36  time: 0.7746  data_time: 0.0092  memory: 12683  loss: 0.0091  decode.loss_ce: 0.0091  decode.acc_seg: 98.3487
2023/06/12 19:51:37 - mmengine - INFO - Iter(train) [ 5450/20000]  lr: 4.7192e-05  eta: 2:27:24  time: 0.7794  data_time: 0.0094  memory: 12683  loss: 0.0308  decode.loss_ce: 0.0308  decode.acc_seg: 100.0000
2023/06/12 19:52:15 - mmengine - INFO - Iter(train) [ 5500/20000]  lr: 4.7030e-05  eta: 2:27:13  time: 0.8038  data_time: 0.0092  memory: 12683  loss: 0.0142  decode.loss_ce: 0.0142  decode.acc_seg: 93.1032
2023/06/12 19:52:51 - mmengine - INFO - Iter(train) [ 5550/20000]  lr: 4.6867e-05  eta: 2:26:58  time: 0.7230  data_time: 0.0120  memory: 12683  loss: 0.0094  decode.loss_ce: 0.0094  decode.acc_seg: 96.7354
2023/06/12 19:53:19 - mmengine - INFO - Iter(train) [ 5600/20000]  lr: 4.6705e-05  eta: 2:26:20  time: 0.4779  data_time: 0.0130  memory: 12683  loss: 0.0043  decode.loss_ce: 0.0043  decode.acc_seg: 99.5764
2023/06/12 19:53:43 - mmengine - INFO - Iter(train) [ 5650/20000]  lr: 4.6543e-05  eta: 2:25:34  time: 0.4895  data_time: 0.0120  memory: 12683  loss: 0.0029  decode.loss_ce: 0.0029  decode.acc_seg: 99.3936
2023/06/12 19:54:08 - mmengine - INFO - Iter(train) [ 5700/20000]  lr: 4.6381e-05  eta: 2:24:49  time: 0.4938  data_time: 0.0133  memory: 12683  loss: 0.0056  decode.loss_ce: 0.0056  decode.acc_seg: 100.0000
2023/06/12 19:54:32 - mmengine - INFO - Iter(train) [ 5750/20000]  lr: 4.6219e-05  eta: 2:24:04  time: 0.4919  data_time: 0.0124  memory: 12683  loss: 0.0046  decode.loss_ce: 0.0046  decode.acc_seg: 97.5694
2023/06/12 19:54:57 - mmengine - INFO - Iter(train) [ 5800/20000]  lr: 4.6057e-05  eta: 2:23:20  time: 0.4921  data_time: 0.0135  memory: 12683  loss: 0.0032  decode.loss_ce: 0.0032  decode.acc_seg: 100.0000
2023/06/12 19:55:22 - mmengine - INFO - Iter(train) [ 5850/20000]  lr: 4.5894e-05  eta: 2:22:36  time: 0.4927  data_time: 0.0134  memory: 12683  loss: 0.0027  decode.loss_ce: 0.0027  decode.acc_seg: 100.0000
2023/06/12 19:55:46 - mmengine - INFO - Iter(train) [ 5900/20000]  lr: 4.5732e-05  eta: 2:21:52  time: 0.4931  data_time: 0.0129  memory: 12683  loss: 0.0077  decode.loss_ce: 0.0077  decode.acc_seg: 97.4340
2023/06/12 19:56:20 - mmengine - INFO - Iter(train) [ 5950/20000]  lr: 4.5570e-05  eta: 2:21:31  time: 0.7192  data_time: 0.0137  memory: 12683  loss: 0.0054  decode.loss_ce: 0.0054  decode.acc_seg: 100.0000
2023/06/12 19:56:51 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 19:56:51 - mmengine - INFO - Iter(train) [ 6000/20000]  lr: 4.5408e-05  eta: 2:21:01  time: 0.4932  data_time: 0.0134  memory: 12683  loss: 0.0023  decode.loss_ce: 0.0023  decode.acc_seg: 100.0000
2023/06/12 19:56:51 - mmengine - INFO - Saving checkpoint at 6000 iterations
2023/06/12 19:56:58 - mmengine - INFO - per class results:
2023/06/12 19:56:58 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
|    Fuel    | 80.54 | 85.34 | 89.22 | 89.22  |   93.47   | 85.34  |
|   Canopy   | 95.15 | 98.35 | 97.52 | 97.52  |   96.69   | 98.35  |
| Background | 87.72 | 96.13 | 93.46 | 93.46  |   90.93   | 96.13  |
|   Trunks   |  nan  |  nan  |  nan  |  nan   |    nan    |  nan   |
+------------+-------+-------+-------+--------+-----------+--------+
2023/06/12 19:56:58 - mmengine - INFO - Iter(val) [6/6]    aAcc: 94.0100  mIoU: 87.8000  mAcc: 93.2700  mDice: 93.4000  mFscore: 93.4000  mPrecision: 93.7000  mRecall: 93.2700  data_time: 0.1473  time: 0.3382
2023/06/12 19:57:22 - mmengine - INFO - Iter(train) [ 6050/20000]  lr: 4.5246e-05  eta: 2:20:18  time: 0.5006  data_time: 0.0122  memory: 12683  loss: 0.0011  decode.loss_ce: 0.0011  decode.acc_seg: 99.8177
2023/06/12 19:57:47 - mmengine - INFO - Iter(train) [ 6100/20000]  lr: 4.5084e-05  eta: 2:19:35  time: 0.4971  data_time: 0.0148  memory: 12683  loss: 0.0036  decode.loss_ce: 0.0036  decode.acc_seg: 99.8799
2023/06/12 19:58:23 - mmengine - INFO - Iter(train) [ 6150/20000]  lr: 4.4921e-05  eta: 2:19:18  time: 0.6898  data_time: 0.0128  memory: 12683  loss: 0.0027  decode.loss_ce: 0.0027  decode.acc_seg: 98.0089
2023/06/12 19:59:01 - mmengine - INFO - Iter(train) [ 6200/20000]  lr: 4.4759e-05  eta: 2:19:05  time: 0.7292  data_time: 0.0132  memory: 12683  loss: 0.0063  decode.loss_ce: 0.0063  decode.acc_seg: 96.5662
2023/06/12 19:59:39 - mmengine - INFO - Iter(train) [ 6250/20000]  lr: 4.4597e-05  eta: 2:18:53  time: 0.8267  data_time: 0.0139  memory: 12683  loss: 0.0025  decode.loss_ce: 0.0025  decode.acc_seg: 99.2072
2023/06/12 20:00:05 - mmengine - INFO - Iter(train) [ 6300/20000]  lr: 4.4435e-05  eta: 2:18:14  time: 0.4908  data_time: 0.0130  memory: 12683  loss: 0.0039  decode.loss_ce: 0.0039  decode.acc_seg: 99.2318
2023/06/12 20:00:30 - mmengine - INFO - Iter(train) [ 6350/20000]  lr: 4.4273e-05  eta: 2:17:31  time: 0.4946  data_time: 0.0144  memory: 12683  loss: 0.0023  decode.loss_ce: 0.0023  decode.acc_seg: 99.7629
2023/06/12 20:00:59 - mmengine - INFO - Iter(train) [ 6400/20000]  lr: 4.4110e-05  eta: 2:16:58  time: 0.8437  data_time: 0.0170  memory: 12683  loss: 0.0014  decode.loss_ce: 0.0014  decode.acc_seg: 100.0000
2023/06/12 20:01:37 - mmengine - INFO - Iter(train) [ 6450/20000]  lr: 4.3948e-05  eta: 2:16:44  time: 0.6790  data_time: 0.0160  memory: 12683  loss: 0.0017  decode.loss_ce: 0.0017  decode.acc_seg: 99.5723
2023/06/12 20:02:12 - mmengine - INFO - Iter(train) [ 6500/20000]  lr: 4.3786e-05  eta: 2:16:24  time: 0.7472  data_time: 0.0158  memory: 12683  loss: 0.0211  decode.loss_ce: 0.0211  decode.acc_seg: 77.0490
2023/06/12 20:02:51 - mmengine - INFO - Iter(train) [ 6550/20000]  lr: 4.3624e-05  eta: 2:16:11  time: 0.7354  data_time: 0.0162  memory: 12683  loss: 0.0021  decode.loss_ce: 0.0021  decode.acc_seg: 96.4964
2023/06/12 20:03:30 - mmengine - INFO - Iter(train) [ 6600/20000]  lr: 4.3462e-05  eta: 2:15:59  time: 0.8067  data_time: 0.0157  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.7461
2023/06/12 20:04:10 - mmengine - INFO - Iter(train) [ 6650/20000]  lr: 4.3300e-05  eta: 2:15:46  time: 0.8323  data_time: 0.0129  memory: 12683  loss: 0.0023  decode.loss_ce: 0.0023  decode.acc_seg: 98.9349
2023/06/12 20:04:48 - mmengine - INFO - Iter(train) [ 6700/20000]  lr: 4.3137e-05  eta: 2:15:32  time: 0.7146  data_time: 0.0135  memory: 12683  loss: 0.0033  decode.loss_ce: 0.0033  decode.acc_seg: 99.8260
2023/06/12 20:05:27 - mmengine - INFO - Iter(train) [ 6750/20000]  lr: 4.2975e-05  eta: 2:15:19  time: 0.7658  data_time: 0.0133  memory: 12683  loss: 0.0032  decode.loss_ce: 0.0032  decode.acc_seg: 99.4568
2023/06/12 20:06:03 - mmengine - INFO - Iter(train) [ 6800/20000]  lr: 4.2813e-05  eta: 2:14:58  time: 0.8145  data_time: 0.0146  memory: 12683  loss: 0.0030  decode.loss_ce: 0.0030  decode.acc_seg: 98.9318
2023/06/12 20:06:39 - mmengine - INFO - Iter(train) [ 6850/20000]  lr: 4.2651e-05  eta: 2:14:38  time: 0.5040  data_time: 0.0147  memory: 12683  loss: 0.0056  decode.loss_ce: 0.0056  decode.acc_seg: 94.2433
2023/06/12 20:07:18 - mmengine - INFO - Iter(train) [ 6900/20000]  lr: 4.2489e-05  eta: 2:14:21  time: 0.7851  data_time: 0.0137  memory: 12683  loss: 0.0080  decode.loss_ce: 0.0080  decode.acc_seg: 99.4274
2023/06/12 20:07:54 - mmengine - INFO - Iter(train) [ 6950/20000]  lr: 4.2327e-05  eta: 2:14:00  time: 0.4968  data_time: 0.0128  memory: 12683  loss: 0.0026  decode.loss_ce: 0.0026  decode.acc_seg: 100.0000
2023/06/12 20:08:18 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 20:08:18 - mmengine - INFO - Iter(train) [ 7000/20000]  lr: 4.2164e-05  eta: 2:13:18  time: 0.4912  data_time: 0.0125  memory: 12683  loss: 0.0040  decode.loss_ce: 0.0040  decode.acc_seg: 99.4972
2023/06/12 20:08:43 - mmengine - INFO - Iter(train) [ 7050/20000]  lr: 4.2002e-05  eta: 2:12:36  time: 0.4896  data_time: 0.0121  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.8456
2023/06/12 20:09:13 - mmengine - INFO - Iter(train) [ 7100/20000]  lr: 4.1840e-05  eta: 2:12:04  time: 0.7239  data_time: 0.0125  memory: 12683  loss: 0.0026  decode.loss_ce: 0.0026  decode.acc_seg: 99.6816
2023/06/12 20:09:51 - mmengine - INFO - Iter(train) [ 7150/20000]  lr: 4.1678e-05  eta: 2:11:47  time: 0.7040  data_time: 0.0121  memory: 12683  loss: 0.0023  decode.loss_ce: 0.0023  decode.acc_seg: 99.3440
2023/06/12 20:10:30 - mmengine - INFO - Iter(train) [ 7200/20000]  lr: 4.1516e-05  eta: 2:11:30  time: 0.8136  data_time: 0.0124  memory: 12683  loss: 0.0012  decode.loss_ce: 0.0012  decode.acc_seg: 99.2320
2023/06/12 20:11:08 - mmengine - INFO - Iter(train) [ 7250/20000]  lr: 4.1354e-05  eta: 2:11:11  time: 0.7499  data_time: 0.0119  memory: 12683  loss: 0.0052  decode.loss_ce: 0.0052  decode.acc_seg: 97.9970
2023/06/12 20:11:45 - mmengine - INFO - Iter(train) [ 7300/20000]  lr: 4.1191e-05  eta: 2:10:53  time: 0.6921  data_time: 0.0124  memory: 12683  loss: 0.0175  decode.loss_ce: 0.0175  decode.acc_seg: 99.4270
2023/06/12 20:12:16 - mmengine - INFO - Iter(train) [ 7350/20000]  lr: 4.1029e-05  eta: 2:10:21  time: 0.5050  data_time: 0.0145  memory: 12683  loss: 0.0103  decode.loss_ce: 0.0103  decode.acc_seg: 99.5518
2023/06/12 20:12:40 - mmengine - INFO - Iter(train) [ 7400/20000]  lr: 4.0867e-05  eta: 2:09:39  time: 0.4919  data_time: 0.0127  memory: 12683  loss: 0.0020  decode.loss_ce: 0.0020  decode.acc_seg: 100.0000
2023/06/12 20:13:05 - mmengine - INFO - Iter(train) [ 7450/20000]  lr: 4.0705e-05  eta: 2:08:58  time: 0.4934  data_time: 0.0130  memory: 12683  loss: 0.0139  decode.loss_ce: 0.0139  decode.acc_seg: 99.1900
2023/06/12 20:13:30 - mmengine - INFO - Iter(train) [ 7500/20000]  lr: 4.0543e-05  eta: 2:08:17  time: 0.4936  data_time: 0.0125  memory: 12683  loss: 0.0037  decode.loss_ce: 0.0037  decode.acc_seg: 98.3316
2023/06/12 20:13:54 - mmengine - INFO - Iter(train) [ 7550/20000]  lr: 4.0381e-05  eta: 2:07:36  time: 0.4935  data_time: 0.0130  memory: 12683  loss: 0.0048  decode.loss_ce: 0.0048  decode.acc_seg: 95.9381
2023/06/12 20:14:19 - mmengine - INFO - Iter(train) [ 7600/20000]  lr: 4.0218e-05  eta: 2:06:55  time: 0.4911  data_time: 0.0123  memory: 12683  loss: 0.0045  decode.loss_ce: 0.0045  decode.acc_seg: 87.3511
2023/06/12 20:14:44 - mmengine - INFO - Iter(train) [ 7650/20000]  lr: 4.0056e-05  eta: 2:06:15  time: 0.5039  data_time: 0.0182  memory: 12683  loss: 0.0113  decode.loss_ce: 0.0113  decode.acc_seg: 98.9604
2023/06/12 20:15:09 - mmengine - INFO - Iter(train) [ 7700/20000]  lr: 3.9894e-05  eta: 2:05:35  time: 0.5002  data_time: 0.0181  memory: 12683  loss: 0.0025  decode.loss_ce: 0.0025  decode.acc_seg: 99.8031
2023/06/12 20:15:34 - mmengine - INFO - Iter(train) [ 7750/20000]  lr: 3.9732e-05  eta: 2:04:56  time: 0.5002  data_time: 0.0185  memory: 12683  loss: 0.0080  decode.loss_ce: 0.0080  decode.acc_seg: 100.0000
2023/06/12 20:15:59 - mmengine - INFO - Iter(train) [ 7800/20000]  lr: 3.9570e-05  eta: 2:04:16  time: 0.5024  data_time: 0.0187  memory: 12683  loss: 0.0090  decode.loss_ce: 0.0090  decode.acc_seg: 98.6686
2023/06/12 20:16:24 - mmengine - INFO - Iter(train) [ 7850/20000]  lr: 3.9408e-05  eta: 2:03:37  time: 0.4996  data_time: 0.0171  memory: 12683  loss: 0.0124  decode.loss_ce: 0.0124  decode.acc_seg: 81.7907
2023/06/12 20:16:49 - mmengine - INFO - Iter(train) [ 7900/20000]  lr: 3.9245e-05  eta: 2:02:58  time: 0.5044  data_time: 0.0184  memory: 12683  loss: 0.0057  decode.loss_ce: 0.0057  decode.acc_seg: 99.1771
2023/06/12 20:17:14 - mmengine - INFO - Iter(train) [ 7950/20000]  lr: 3.9083e-05  eta: 2:02:20  time: 0.4958  data_time: 0.0165  memory: 12683  loss: 0.0024  decode.loss_ce: 0.0024  decode.acc_seg: 98.1307
2023/06/12 20:17:39 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 20:17:39 - mmengine - INFO - Iter(train) [ 8000/20000]  lr: 3.8921e-05  eta: 2:01:41  time: 0.5038  data_time: 0.0181  memory: 12683  loss: 0.0026  decode.loss_ce: 0.0026  decode.acc_seg: 99.9935
2023/06/12 20:17:40 - mmengine - INFO - Saving checkpoint at 8000 iterations
2023/06/12 20:17:46 - mmengine - INFO - per class results:
2023/06/12 20:17:46 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
|    Fuel    | 82.37 | 88.71 | 90.33 | 90.33  |   92.02   | 88.71  |
|   Canopy   | 95.58 | 97.38 | 97.74 | 97.74  |    98.1   | 97.38  |
| Background | 88.48 | 95.92 | 93.89 | 93.89  |   91.94   | 95.92  |
|   Trunks   |  nan  |  nan  |  nan  |  nan   |    nan    |  nan   |
+------------+-------+-------+-------+--------+-----------+--------+
2023/06/12 20:17:46 - mmengine - INFO - Iter(val) [6/6]    aAcc: 94.4900  mIoU: 88.8100  mAcc: 94.0000  mDice: 93.9900  mFscore: 93.9900  mPrecision: 94.0200  mRecall: 94.0000  data_time: 0.1454  time: 0.3361
2023/06/12 20:18:11 - mmengine - INFO - Iter(train) [ 8050/20000]  lr: 3.8759e-05  eta: 2:01:03  time: 0.4897  data_time: 0.0134  memory: 12683  loss: 0.0062  decode.loss_ce: 0.0062  decode.acc_seg: 99.6061
2023/06/12 20:18:36 - mmengine - INFO - Iter(train) [ 8100/20000]  lr: 3.8597e-05  eta: 2:00:23  time: 0.4833  data_time: 0.0109  memory: 12683  loss: 0.0045  decode.loss_ce: 0.0045  decode.acc_seg: 99.9629
2023/06/12 20:19:00 - mmengine - INFO - Iter(train) [ 8150/20000]  lr: 3.8435e-05  eta: 1:59:44  time: 0.4920  data_time: 0.0130  memory: 12683  loss: 0.0023  decode.loss_ce: 0.0023  decode.acc_seg: 98.8655
2023/06/12 20:19:25 - mmengine - INFO - Iter(train) [ 8200/20000]  lr: 3.8272e-05  eta: 1:59:06  time: 0.4987  data_time: 0.0185  memory: 12683  loss: 0.0026  decode.loss_ce: 0.0026  decode.acc_seg: 95.8245
2023/06/12 20:19:49 - mmengine - INFO - Iter(train) [ 8250/20000]  lr: 3.8110e-05  eta: 1:58:27  time: 0.4961  data_time: 0.0168  memory: 12683  loss: 0.0021  decode.loss_ce: 0.0021  decode.acc_seg: 99.9756
2023/06/12 20:20:14 - mmengine - INFO - Iter(train) [ 8300/20000]  lr: 3.7948e-05  eta: 1:57:49  time: 0.4924  data_time: 0.0140  memory: 12683  loss: 0.0022  decode.loss_ce: 0.0022  decode.acc_seg: 99.9931
2023/06/12 20:20:38 - mmengine - INFO - Iter(train) [ 8350/20000]  lr: 3.7786e-05  eta: 1:57:11  time: 0.4901  data_time: 0.0130  memory: 12683  loss: 0.0032  decode.loss_ce: 0.0032  decode.acc_seg: 99.9876
2023/06/12 20:21:03 - mmengine - INFO - Iter(train) [ 8400/20000]  lr: 3.7624e-05  eta: 1:56:33  time: 0.4900  data_time: 0.0133  memory: 12683  loss: 0.0046  decode.loss_ce: 0.0046  decode.acc_seg: 100.0000
2023/06/12 20:21:27 - mmengine - INFO - Iter(train) [ 8450/20000]  lr: 3.7461e-05  eta: 1:55:55  time: 0.4900  data_time: 0.0126  memory: 12683  loss: 0.0016  decode.loss_ce: 0.0016  decode.acc_seg: 96.7551
2023/06/12 20:21:52 - mmengine - INFO - Iter(train) [ 8500/20000]  lr: 3.7299e-05  eta: 1:55:17  time: 0.4912  data_time: 0.0135  memory: 12683  loss: 0.0016  decode.loss_ce: 0.0016  decode.acc_seg: 98.9275
2023/06/12 20:22:17 - mmengine - INFO - Iter(train) [ 8550/20000]  lr: 3.7137e-05  eta: 1:54:40  time: 0.4903  data_time: 0.0152  memory: 12683  loss: 0.0047  decode.loss_ce: 0.0047  decode.acc_seg: 97.2513
2023/06/12 20:22:41 - mmengine - INFO - Iter(train) [ 8600/20000]  lr: 3.6975e-05  eta: 1:54:03  time: 0.4894  data_time: 0.0137  memory: 12683  loss: 0.0049  decode.loss_ce: 0.0049  decode.acc_seg: 100.0000
2023/06/12 20:23:06 - mmengine - INFO - Iter(train) [ 8650/20000]  lr: 3.6813e-05  eta: 1:53:25  time: 0.4909  data_time: 0.0125  memory: 12683  loss: 0.0056  decode.loss_ce: 0.0056  decode.acc_seg: 100.0000
2023/06/12 20:23:30 - mmengine - INFO - Iter(train) [ 8700/20000]  lr: 3.6651e-05  eta: 1:52:48  time: 0.4897  data_time: 0.0127  memory: 12683  loss: 0.0029  decode.loss_ce: 0.0029  decode.acc_seg: 100.0000
2023/06/12 20:23:55 - mmengine - INFO - Iter(train) [ 8750/20000]  lr: 3.6488e-05  eta: 1:52:11  time: 0.4916  data_time: 0.0161  memory: 12683  loss: 0.0033  decode.loss_ce: 0.0033  decode.acc_seg: 99.7870
2023/06/12 20:24:19 - mmengine - INFO - Iter(train) [ 8800/20000]  lr: 3.6326e-05  eta: 1:51:35  time: 0.4918  data_time: 0.0147  memory: 12683  loss: 0.0034  decode.loss_ce: 0.0034  decode.acc_seg: 98.7738
2023/06/12 20:24:44 - mmengine - INFO - Iter(train) [ 8850/20000]  lr: 3.6164e-05  eta: 1:50:59  time: 0.4961  data_time: 0.0148  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.9377
2023/06/12 20:25:09 - mmengine - INFO - Iter(train) [ 8900/20000]  lr: 3.6002e-05  eta: 1:50:22  time: 0.4943  data_time: 0.0158  memory: 12683  loss: 0.0015  decode.loss_ce: 0.0015  decode.acc_seg: 99.9203
2023/06/12 20:25:34 - mmengine - INFO - Iter(train) [ 8950/20000]  lr: 3.5840e-05  eta: 1:49:46  time: 0.4921  data_time: 0.0140  memory: 12683  loss: 0.0016  decode.loss_ce: 0.0016  decode.acc_seg: 99.0552
2023/06/12 20:25:58 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 20:25:58 - mmengine - INFO - Iter(train) [ 9000/20000]  lr: 3.5678e-05  eta: 1:49:10  time: 0.4945  data_time: 0.0157  memory: 12683  loss: 0.0016  decode.loss_ce: 0.0016  decode.acc_seg: 99.8376
2023/06/12 20:26:23 - mmengine - INFO - Iter(train) [ 9050/20000]  lr: 3.5515e-05  eta: 1:48:34  time: 0.4914  data_time: 0.0145  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.5769
2023/06/12 20:26:50 - mmengine - INFO - Iter(train) [ 9100/20000]  lr: 3.5353e-05  eta: 1:48:02  time: 0.7622  data_time: 0.0122  memory: 12683  loss: 0.0029  decode.loss_ce: 0.0029  decode.acc_seg: 99.6183
2023/06/12 20:27:29 - mmengine - INFO - Iter(train) [ 9150/20000]  lr: 3.5191e-05  eta: 1:47:42  time: 0.8144  data_time: 0.0122  memory: 12683  loss: 0.0013  decode.loss_ce: 0.0013  decode.acc_seg: 98.4040
2023/06/12 20:28:07 - mmengine - INFO - Iter(train) [ 9200/20000]  lr: 3.5029e-05  eta: 1:47:22  time: 0.7591  data_time: 0.0142  memory: 12683  loss: 0.0085  decode.loss_ce: 0.0085  decode.acc_seg: 98.8633
2023/06/12 20:28:46 - mmengine - INFO - Iter(train) [ 9250/20000]  lr: 3.4867e-05  eta: 1:47:03  time: 0.8380  data_time: 0.0127  memory: 12683  loss: 0.0023  decode.loss_ce: 0.0023  decode.acc_seg: 99.1915
2023/06/12 20:29:25 - mmengine - INFO - Iter(train) [ 9300/20000]  lr: 3.4705e-05  eta: 1:46:43  time: 0.7229  data_time: 0.0128  memory: 12683  loss: 0.0019  decode.loss_ce: 0.0019  decode.acc_seg: 99.3210
2023/06/12 20:30:04 - mmengine - INFO - Iter(train) [ 9350/20000]  lr: 3.4542e-05  eta: 1:46:24  time: 0.7588  data_time: 0.0137  memory: 12683  loss: 0.0022  decode.loss_ce: 0.0022  decode.acc_seg: 100.0000
2023/06/12 20:30:43 - mmengine - INFO - Iter(train) [ 9400/20000]  lr: 3.4380e-05  eta: 1:46:04  time: 0.8371  data_time: 0.0129  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.6012
2023/06/12 20:31:22 - mmengine - INFO - Iter(train) [ 9450/20000]  lr: 3.4218e-05  eta: 1:45:44  time: 0.7463  data_time: 0.0125  memory: 12683  loss: 0.0017  decode.loss_ce: 0.0017  decode.acc_seg: 99.8641
2023/06/12 20:32:01 - mmengine - INFO - Iter(train) [ 9500/20000]  lr: 3.4056e-05  eta: 1:45:24  time: 0.7410  data_time: 0.0123  memory: 12683  loss: 0.0015  decode.loss_ce: 0.0015  decode.acc_seg: 99.8131
2023/06/12 20:32:40 - mmengine - INFO - Iter(train) [ 9550/20000]  lr: 3.3894e-05  eta: 1:45:04  time: 0.7989  data_time: 0.0125  memory: 12683  loss: 0.0028  decode.loss_ce: 0.0028  decode.acc_seg: 95.9529
2023/06/12 20:33:19 - mmengine - INFO - Iter(train) [ 9600/20000]  lr: 3.3732e-05  eta: 1:44:43  time: 0.7477  data_time: 0.0126  memory: 12683  loss: 0.0013  decode.loss_ce: 0.0013  decode.acc_seg: 99.4047
2023/06/12 20:33:58 - mmengine - INFO - Iter(train) [ 9650/20000]  lr: 3.3569e-05  eta: 1:44:22  time: 0.7463  data_time: 0.0138  memory: 12683  loss: 0.0055  decode.loss_ce: 0.0055  decode.acc_seg: 99.6836
2023/06/12 20:34:37 - mmengine - INFO - Iter(train) [ 9700/20000]  lr: 3.3407e-05  eta: 1:44:01  time: 0.8309  data_time: 0.0142  memory: 12683  loss: 0.0037  decode.loss_ce: 0.0037  decode.acc_seg: 100.0000
2023/06/12 20:35:15 - mmengine - INFO - Iter(train) [ 9750/20000]  lr: 3.3245e-05  eta: 1:43:40  time: 0.7431  data_time: 0.0130  memory: 12683  loss: 0.0050  decode.loss_ce: 0.0050  decode.acc_seg: 100.0000
2023/06/12 20:35:54 - mmengine - INFO - Iter(train) [ 9800/20000]  lr: 3.3083e-05  eta: 1:43:18  time: 0.7716  data_time: 0.0130  memory: 12683  loss: 0.0029  decode.loss_ce: 0.0029  decode.acc_seg: 95.5591
2023/06/12 20:36:32 - mmengine - INFO - Iter(train) [ 9850/20000]  lr: 3.2921e-05  eta: 1:42:56  time: 0.7625  data_time: 0.0143  memory: 12683  loss: 0.0014  decode.loss_ce: 0.0014  decode.acc_seg: 100.0000
2023/06/12 20:37:10 - mmengine - INFO - Iter(train) [ 9900/20000]  lr: 3.2759e-05  eta: 1:42:32  time: 0.6896  data_time: 0.0157  memory: 12683  loss: 0.0014  decode.loss_ce: 0.0014  decode.acc_seg: 99.6768
2023/06/12 20:37:48 - mmengine - INFO - Iter(train) [ 9950/20000]  lr: 3.2596e-05  eta: 1:42:10  time: 0.7875  data_time: 0.0158  memory: 12683  loss: 0.0012  decode.loss_ce: 0.0012  decode.acc_seg: 99.3351
2023/06/12 20:38:27 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 20:38:27 - mmengine - INFO - Iter(train) [10000/20000]  lr: 3.2434e-05  eta: 1:41:47  time: 0.8268  data_time: 0.0154  memory: 12683  loss: 0.0024  decode.loss_ce: 0.0024  decode.acc_seg: 100.0000
2023/06/12 20:38:27 - mmengine - INFO - Saving checkpoint at 10000 iterations
2023/06/12 20:38:35 - mmengine - INFO - per class results:
2023/06/12 20:38:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
|    Fuel    | 80.64 | 85.51 | 89.28 | 89.28  |   93.41   | 85.51  |
|   Canopy   | 95.87 | 98.12 | 97.89 | 97.89  |   97.67   | 98.12  |
| Background | 87.74 | 96.84 | 93.47 | 93.47  |   90.33   | 96.84  |
|   Trunks   |  nan  |  nan  |  nan  |  nan   |    nan    |  nan   |
+------------+-------+-------+-------+--------+-----------+--------+
2023/06/12 20:38:35 - mmengine - INFO - Iter(val) [6/6]    aAcc: 94.1700  mIoU: 88.0900  mAcc: 93.4900  mDice: 93.5500  mFscore: 93.5500  mPrecision: 93.8000  mRecall: 93.4900  data_time: 0.1361  time: 0.6026
2023/06/12 20:39:28 - mmengine - INFO - Iter(train) [10050/20000]  lr: 3.2272e-05  eta: 1:41:40  time: 0.9304  data_time: 0.0153  memory: 12683  loss: 0.0046  decode.loss_ce: 0.0046  decode.acc_seg: 99.9747
2023/06/12 20:40:25 - mmengine - INFO - Iter(train) [10100/20000]  lr: 3.2110e-05  eta: 1:41:34  time: 1.2250  data_time: 0.0173  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.3838
2023/06/12 20:41:24 - mmengine - INFO - Iter(train) [10150/20000]  lr: 3.1948e-05  eta: 1:41:31  time: 1.1269  data_time: 0.0178  memory: 12683  loss: 0.0049  decode.loss_ce: 0.0049  decode.acc_seg: 99.4102
2023/06/12 20:42:18 - mmengine - INFO - Iter(train) [10200/20000]  lr: 3.1786e-05  eta: 1:41:22  time: 1.1353  data_time: 0.0161  memory: 12683  loss: 0.0015  decode.loss_ce: 0.0015  decode.acc_seg: 99.7607
2023/06/12 20:43:10 - mmengine - INFO - Iter(train) [10250/20000]  lr: 3.1623e-05  eta: 1:41:11  time: 0.9787  data_time: 0.0144  memory: 12683  loss: 0.0010  decode.loss_ce: 0.0010  decode.acc_seg: 99.8261
2023/06/12 20:44:05 - mmengine - INFO - Iter(train) [10300/20000]  lr: 3.1461e-05  eta: 1:41:02  time: 1.0398  data_time: 0.0163  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 100.0000
2023/06/12 20:44:58 - mmengine - INFO - Iter(train) [10350/20000]  lr: 3.1299e-05  eta: 1:40:52  time: 1.1703  data_time: 0.0154  memory: 12683  loss: 0.0011  decode.loss_ce: 0.0011  decode.acc_seg: 97.5411
2023/06/12 20:45:53 - mmengine - INFO - Iter(train) [10400/20000]  lr: 3.1137e-05  eta: 1:40:42  time: 0.7750  data_time: 0.0148  memory: 12683  loss: 0.0010  decode.loss_ce: 0.0010  decode.acc_seg: 100.0000
2023/06/12 20:46:43 - mmengine - INFO - Iter(train) [10450/20000]  lr: 3.0975e-05  eta: 1:40:28  time: 1.0661  data_time: 0.0165  memory: 12683  loss: 0.0024  decode.loss_ce: 0.0024  decode.acc_seg: 100.0000
2023/06/12 20:47:37 - mmengine - INFO - Iter(train) [10500/20000]  lr: 3.0812e-05  eta: 1:40:16  time: 1.0700  data_time: 0.0154  memory: 12683  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000
2023/06/12 20:48:26 - mmengine - INFO - Iter(train) [10550/20000]  lr: 3.0650e-05  eta: 1:40:00  time: 1.1273  data_time: 0.0124  memory: 12683  loss: 0.0019  decode.loss_ce: 0.0019  decode.acc_seg: 99.8923
2023/06/12 20:49:24 - mmengine - INFO - Iter(train) [10600/20000]  lr: 3.0488e-05  eta: 1:39:51  time: 1.0657  data_time: 0.0157  memory: 12683  loss: 0.0027  decode.loss_ce: 0.0027  decode.acc_seg: 99.8877
2023/06/12 20:50:20 - mmengine - INFO - Iter(train) [10650/20000]  lr: 3.0326e-05  eta: 1:39:41  time: 1.0023  data_time: 0.0158  memory: 12683  loss: 0.0037  decode.loss_ce: 0.0037  decode.acc_seg: 68.6520
2023/06/12 20:51:17 - mmengine - INFO - Iter(train) [10700/20000]  lr: 3.0164e-05  eta: 1:39:31  time: 1.2131  data_time: 0.0159  memory: 12683  loss: 0.0016  decode.loss_ce: 0.0016  decode.acc_seg: 99.9401
2023/06/12 20:52:16 - mmengine - INFO - Iter(train) [10750/20000]  lr: 3.0002e-05  eta: 1:39:22  time: 1.1982  data_time: 0.0162  memory: 12683  loss: 0.0011  decode.loss_ce: 0.0011  decode.acc_seg: 99.6882
2023/06/12 20:53:15 - mmengine - INFO - Iter(train) [10800/20000]  lr: 2.9839e-05  eta: 1:39:12  time: 1.0944  data_time: 0.0156  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 99.9898
2023/06/12 20:54:01 - mmengine - INFO - Iter(train) [10850/20000]  lr: 2.9677e-05  eta: 1:38:51  time: 1.1109  data_time: 0.0143  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.8696
2023/06/12 20:54:57 - mmengine - INFO - Iter(train) [10900/20000]  lr: 2.9515e-05  eta: 1:38:38  time: 1.2050  data_time: 0.0162  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 100.0000
2023/06/12 20:55:45 - mmengine - INFO - Iter(train) [10950/20000]  lr: 2.9353e-05  eta: 1:38:19  time: 0.7827  data_time: 0.0136  memory: 12683  loss: 0.0011  decode.loss_ce: 0.0011  decode.acc_seg: 99.4037
2023/06/12 20:56:18 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 20:56:18 - mmengine - INFO - Iter(train) [11000/20000]  lr: 2.9191e-05  eta: 1:37:47  time: 0.4909  data_time: 0.0123  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.9872
2023/06/12 20:56:42 - mmengine - INFO - Iter(train) [11050/20000]  lr: 2.9029e-05  eta: 1:37:08  time: 0.4903  data_time: 0.0124  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.5445
2023/06/12 20:57:07 - mmengine - INFO - Iter(train) [11100/20000]  lr: 2.8866e-05  eta: 1:36:29  time: 0.4894  data_time: 0.0121  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.9689
2023/06/12 20:57:32 - mmengine - INFO - Iter(train) [11150/20000]  lr: 2.8704e-05  eta: 1:35:50  time: 0.4903  data_time: 0.0122  memory: 12683  loss: 0.0012  decode.loss_ce: 0.0012  decode.acc_seg: 99.5802
2023/06/12 20:57:56 - mmengine - INFO - Iter(train) [11200/20000]  lr: 2.8542e-05  eta: 1:35:11  time: 0.4953  data_time: 0.0151  memory: 12683  loss: 0.0020  decode.loss_ce: 0.0020  decode.acc_seg: 99.9943
2023/06/12 20:58:24 - mmengine - INFO - Iter(train) [11250/20000]  lr: 2.8380e-05  eta: 1:34:35  time: 0.4954  data_time: 0.0158  memory: 12683  loss: 0.0013  decode.loss_ce: 0.0013  decode.acc_seg: 98.5423
2023/06/12 20:58:48 - mmengine - INFO - Iter(train) [11300/20000]  lr: 2.8218e-05  eta: 1:33:56  time: 0.4922  data_time: 0.0136  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 98.4742
2023/06/12 20:59:15 - mmengine - INFO - Iter(train) [11350/20000]  lr: 2.8056e-05  eta: 1:33:20  time: 0.4894  data_time: 0.0125  memory: 12683  loss: 0.0012  decode.loss_ce: 0.0012  decode.acc_seg: 99.8246
2023/06/12 20:59:42 - mmengine - INFO - Iter(train) [11400/20000]  lr: 2.7893e-05  eta: 1:32:43  time: 0.4900  data_time: 0.0127  memory: 12683  loss: 0.0242  decode.loss_ce: 0.0242  decode.acc_seg: 94.5252
2023/06/12 21:00:10 - mmengine - INFO - Iter(train) [11450/20000]  lr: 2.7731e-05  eta: 1:32:08  time: 0.4904  data_time: 0.0123  memory: 12683  loss: 0.0096  decode.loss_ce: 0.0096  decode.acc_seg: 99.1674
2023/06/12 21:00:39 - mmengine - INFO - Iter(train) [11500/20000]  lr: 2.7569e-05  eta: 1:31:33  time: 0.5502  data_time: 0.0135  memory: 12683  loss: 0.0037  decode.loss_ce: 0.0037  decode.acc_seg: 100.0000
2023/06/12 21:01:03 - mmengine - INFO - Iter(train) [11550/20000]  lr: 2.7407e-05  eta: 1:30:55  time: 0.4918  data_time: 0.0130  memory: 12683  loss: 0.0020  decode.loss_ce: 0.0020  decode.acc_seg: 99.2071
2023/06/12 21:01:28 - mmengine - INFO - Iter(train) [11600/20000]  lr: 2.7245e-05  eta: 1:30:17  time: 0.4914  data_time: 0.0122  memory: 12683  loss: 0.0043  decode.loss_ce: 0.0043  decode.acc_seg: 98.5533
2023/06/12 21:01:52 - mmengine - INFO - Iter(train) [11650/20000]  lr: 2.7083e-05  eta: 1:29:39  time: 0.4898  data_time: 0.0120  memory: 12683  loss: 0.0080  decode.loss_ce: 0.0080  decode.acc_seg: 99.2760
2023/06/12 21:02:17 - mmengine - INFO - Iter(train) [11700/20000]  lr: 2.6920e-05  eta: 1:29:01  time: 0.4894  data_time: 0.0145  memory: 12683  loss: 0.0023  decode.loss_ce: 0.0023  decode.acc_seg: 99.8190
2023/06/12 21:02:44 - mmengine - INFO - Iter(train) [11750/20000]  lr: 2.6758e-05  eta: 1:28:26  time: 0.5076  data_time: 0.0128  memory: 12683  loss: 0.0012  decode.loss_ce: 0.0012  decode.acc_seg: 99.8937
2023/06/12 21:03:24 - mmengine - INFO - Iter(train) [11800/20000]  lr: 2.6596e-05  eta: 1:27:59  time: 0.8164  data_time: 0.0140  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 100.0000
2023/06/12 21:04:03 - mmengine - INFO - Iter(train) [11850/20000]  lr: 2.6434e-05  eta: 1:27:31  time: 0.7389  data_time: 0.0151  memory: 12683  loss: 0.0019  decode.loss_ce: 0.0019  decode.acc_seg: 100.0000
2023/06/12 21:04:42 - mmengine - INFO - Iter(train) [11900/20000]  lr: 2.6272e-05  eta: 1:27:04  time: 0.8125  data_time: 0.0134  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 100.0000
2023/06/12 21:05:20 - mmengine - INFO - Iter(train) [11950/20000]  lr: 2.6110e-05  eta: 1:26:35  time: 0.7115  data_time: 0.0122  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 99.9078
2023/06/12 21:05:57 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 21:05:57 - mmengine - INFO - Iter(train) [12000/20000]  lr: 2.5947e-05  eta: 1:26:06  time: 0.6767  data_time: 0.0113  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 100.0000
2023/06/12 21:05:57 - mmengine - INFO - Saving checkpoint at 12000 iterations
2023/06/12 21:06:03 - mmengine - INFO - per class results:
2023/06/12 21:06:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
|    Fuel    | 79.75 |  85.3 | 88.73 | 88.73  |   92.45   |  85.3  |
|   Canopy   | 95.79 | 97.87 | 97.85 | 97.85  |   97.83   | 97.87  |
| Background |  86.7 | 96.17 | 92.87 | 92.87  |   89.79   | 96.17  |
|   Trunks   |  nan  |  nan  |  nan  |  nan   |    nan    |  nan   |
+------------+-------+-------+-------+--------+-----------+--------+
2023/06/12 21:06:03 - mmengine - INFO - Iter(val) [6/6]    aAcc: 93.8100  mIoU: 87.4100  mAcc: 93.1100  mDice: 93.1500  mFscore: 93.1500  mPrecision: 93.3600  mRecall: 93.1100  data_time: 0.1414  time: 0.4675
2023/06/12 21:06:41 - mmengine - INFO - Iter(train) [12050/20000]  lr: 2.5785e-05  eta: 1:25:37  time: 0.7307  data_time: 0.0126  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 99.5558
2023/06/12 21:07:19 - mmengine - INFO - Iter(train) [12100/20000]  lr: 2.5623e-05  eta: 1:25:09  time: 0.8126  data_time: 0.0118  memory: 12683  loss: 0.0024  decode.loss_ce: 0.0024  decode.acc_seg: 97.9277
2023/06/12 21:07:57 - mmengine - INFO - Iter(train) [12150/20000]  lr: 2.5461e-05  eta: 1:24:40  time: 0.7047  data_time: 0.0119  memory: 12683  loss: 0.0028  decode.loss_ce: 0.0028  decode.acc_seg: 100.0000
2023/06/12 21:08:36 - mmengine - INFO - Iter(train) [12200/20000]  lr: 2.5299e-05  eta: 1:24:12  time: 0.8325  data_time: 0.0119  memory: 12683  loss: 0.0022  decode.loss_ce: 0.0022  decode.acc_seg: 100.0000
2023/06/12 21:09:14 - mmengine - INFO - Iter(train) [12250/20000]  lr: 2.5136e-05  eta: 1:23:43  time: 0.7228  data_time: 0.0123  memory: 12683  loss: 0.0013  decode.loss_ce: 0.0013  decode.acc_seg: 99.9094
2023/06/12 21:09:52 - mmengine - INFO - Iter(train) [12300/20000]  lr: 2.4974e-05  eta: 1:23:14  time: 0.7738  data_time: 0.0118  memory: 12683  loss: 0.0014  decode.loss_ce: 0.0014  decode.acc_seg: 99.5260
2023/06/12 21:10:30 - mmengine - INFO - Iter(train) [12350/20000]  lr: 2.4812e-05  eta: 1:22:46  time: 0.8054  data_time: 0.0119  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.2403
2023/06/12 21:11:08 - mmengine - INFO - Iter(train) [12400/20000]  lr: 2.4650e-05  eta: 1:22:16  time: 0.7221  data_time: 0.0116  memory: 12683  loss: 0.0017  decode.loss_ce: 0.0017  decode.acc_seg: 99.8548
2023/06/12 21:11:47 - mmengine - INFO - Iter(train) [12450/20000]  lr: 2.4488e-05  eta: 1:21:48  time: 0.8177  data_time: 0.0119  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.7756
2023/06/12 21:12:25 - mmengine - INFO - Iter(train) [12500/20000]  lr: 2.4326e-05  eta: 1:21:18  time: 0.6939  data_time: 0.0117  memory: 12683  loss: 0.0026  decode.loss_ce: 0.0026  decode.acc_seg: 98.1919
2023/06/12 21:13:03 - mmengine - INFO - Iter(train) [12550/20000]  lr: 2.4163e-05  eta: 1:20:49  time: 0.7161  data_time: 0.0125  memory: 12683  loss: 0.0017  decode.loss_ce: 0.0017  decode.acc_seg: 99.8032
2023/06/12 21:13:42 - mmengine - INFO - Iter(train) [12600/20000]  lr: 2.4001e-05  eta: 1:20:20  time: 0.8149  data_time: 0.0118  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 100.0000
2023/06/12 21:14:19 - mmengine - INFO - Iter(train) [12650/20000]  lr: 2.3839e-05  eta: 1:19:50  time: 0.7400  data_time: 0.0118  memory: 12683  loss: 0.0014  decode.loss_ce: 0.0014  decode.acc_seg: 100.0000
2023/06/12 21:14:58 - mmengine - INFO - Iter(train) [12700/20000]  lr: 2.3677e-05  eta: 1:19:22  time: 0.8119  data_time: 0.0119  memory: 12683  loss: 0.0010  decode.loss_ce: 0.0010  decode.acc_seg: 99.9886
2023/06/12 21:15:37 - mmengine - INFO - Iter(train) [12750/20000]  lr: 2.3515e-05  eta: 1:18:53  time: 0.8182  data_time: 0.0131  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000
2023/06/12 21:16:16 - mmengine - INFO - Iter(train) [12800/20000]  lr: 2.3353e-05  eta: 1:18:24  time: 0.7798  data_time: 0.0138  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 99.9966
2023/06/12 21:16:55 - mmengine - INFO - Iter(train) [12850/20000]  lr: 2.3190e-05  eta: 1:17:54  time: 0.7210  data_time: 0.0122  memory: 12683  loss: 0.0014  decode.loss_ce: 0.0014  decode.acc_seg: 100.0000
2023/06/12 21:17:34 - mmengine - INFO - Iter(train) [12900/20000]  lr: 2.3028e-05  eta: 1:17:25  time: 0.7872  data_time: 0.0124  memory: 12683  loss: 0.0017  decode.loss_ce: 0.0017  decode.acc_seg: 100.0000
2023/06/12 21:18:13 - mmengine - INFO - Iter(train) [12950/20000]  lr: 2.2866e-05  eta: 1:16:56  time: 0.8186  data_time: 0.0137  memory: 12683  loss: 0.0031  decode.loss_ce: 0.0031  decode.acc_seg: 100.0000
2023/06/12 21:18:52 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 21:18:52 - mmengine - INFO - Iter(train) [13000/20000]  lr: 2.2704e-05  eta: 1:16:27  time: 0.7704  data_time: 0.0124  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.9179
2023/06/12 21:19:31 - mmengine - INFO - Iter(train) [13050/20000]  lr: 2.2542e-05  eta: 1:15:57  time: 0.7304  data_time: 0.0123  memory: 12683  loss: 0.0012  decode.loss_ce: 0.0012  decode.acc_seg: 100.0000
2023/06/12 21:20:11 - mmengine - INFO - Iter(train) [13100/20000]  lr: 2.2380e-05  eta: 1:15:28  time: 0.8330  data_time: 0.0126  memory: 12683  loss: 0.0025  decode.loss_ce: 0.0025  decode.acc_seg: 98.4777
2023/06/12 21:20:50 - mmengine - INFO - Iter(train) [13150/20000]  lr: 2.2217e-05  eta: 1:14:58  time: 0.8222  data_time: 0.0125  memory: 12683  loss: 0.0027  decode.loss_ce: 0.0027  decode.acc_seg: 99.8530
2023/06/12 21:21:29 - mmengine - INFO - Iter(train) [13200/20000]  lr: 2.2055e-05  eta: 1:14:29  time: 0.8271  data_time: 0.0130  memory: 12683  loss: 0.0215  decode.loss_ce: 0.0215  decode.acc_seg: 98.2162
2023/06/12 21:22:08 - mmengine - INFO - Iter(train) [13250/20000]  lr: 2.1893e-05  eta: 1:13:59  time: 0.7274  data_time: 0.0135  memory: 12683  loss: 0.0013  decode.loss_ce: 0.0013  decode.acc_seg: 100.0000
2023/06/12 21:22:47 - mmengine - INFO - Iter(train) [13300/20000]  lr: 2.1731e-05  eta: 1:13:29  time: 0.7726  data_time: 0.0137  memory: 12683  loss: 0.0026  decode.loss_ce: 0.0026  decode.acc_seg: 99.4801
2023/06/12 21:23:27 - mmengine - INFO - Iter(train) [13350/20000]  lr: 2.1569e-05  eta: 1:13:00  time: 0.8555  data_time: 0.0138  memory: 12683  loss: 0.0030  decode.loss_ce: 0.0030  decode.acc_seg: 99.6517
2023/06/12 21:24:05 - mmengine - INFO - Iter(train) [13400/20000]  lr: 2.1407e-05  eta: 1:12:29  time: 0.7768  data_time: 0.0127  memory: 12683  loss: 0.0018  decode.loss_ce: 0.0018  decode.acc_seg: 98.1829
2023/06/12 21:24:44 - mmengine - INFO - Iter(train) [13450/20000]  lr: 2.1244e-05  eta: 1:12:00  time: 0.7416  data_time: 0.0127  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.9598
2023/06/12 21:25:23 - mmengine - INFO - Iter(train) [13500/20000]  lr: 2.1082e-05  eta: 1:11:29  time: 0.7539  data_time: 0.0123  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.8870
2023/06/12 21:26:03 - mmengine - INFO - Iter(train) [13550/20000]  lr: 2.0920e-05  eta: 1:11:00  time: 0.8466  data_time: 0.0119  memory: 12683  loss: 0.0022  decode.loss_ce: 0.0022  decode.acc_seg: 100.0000
2023/06/12 21:26:42 - mmengine - INFO - Iter(train) [13600/20000]  lr: 2.0758e-05  eta: 1:10:29  time: 0.8289  data_time: 0.0122  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.0187
2023/06/12 21:27:21 - mmengine - INFO - Iter(train) [13650/20000]  lr: 2.0596e-05  eta: 1:09:59  time: 0.7723  data_time: 0.0125  memory: 12683  loss: 0.0027  decode.loss_ce: 0.0027  decode.acc_seg: 100.0000
2023/06/12 21:28:00 - mmengine - INFO - Iter(train) [13700/20000]  lr: 2.0434e-05  eta: 1:09:29  time: 0.6822  data_time: 0.0123  memory: 12683  loss: 0.0011  decode.loss_ce: 0.0011  decode.acc_seg: 99.6089
2023/06/12 21:28:39 - mmengine - INFO - Iter(train) [13750/20000]  lr: 2.0271e-05  eta: 1:08:58  time: 0.7941  data_time: 0.0123  memory: 12683  loss: 0.0016  decode.loss_ce: 0.0016  decode.acc_seg: 99.8209
2023/06/12 21:29:18 - mmengine - INFO - Iter(train) [13800/20000]  lr: 2.0109e-05  eta: 1:08:28  time: 0.8164  data_time: 0.0144  memory: 12683  loss: 0.0020  decode.loss_ce: 0.0020  decode.acc_seg: 100.0000
2023/06/12 21:29:56 - mmengine - INFO - Iter(train) [13850/20000]  lr: 1.9947e-05  eta: 1:07:57  time: 0.7200  data_time: 0.0126  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.9990
2023/06/12 21:30:36 - mmengine - INFO - Iter(train) [13900/20000]  lr: 1.9785e-05  eta: 1:07:27  time: 0.8262  data_time: 0.0128  memory: 12683  loss: 0.0016  decode.loss_ce: 0.0016  decode.acc_seg: 100.0000
2023/06/12 21:31:15 - mmengine - INFO - Iter(train) [13950/20000]  lr: 1.9623e-05  eta: 1:06:56  time: 0.8156  data_time: 0.0131  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 100.0000
2023/06/12 21:31:53 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 21:31:53 - mmengine - INFO - Iter(train) [14000/20000]  lr: 1.9461e-05  eta: 1:06:25  time: 0.7022  data_time: 0.0141  memory: 12683  loss: 0.0013  decode.loss_ce: 0.0013  decode.acc_seg: 100.0000
2023/06/12 21:31:53 - mmengine - INFO - Saving checkpoint at 14000 iterations
2023/06/12 21:32:01 - mmengine - INFO - per class results:
2023/06/12 21:32:01 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
|    Fuel    | 78.78 | 83.22 | 88.13 | 88.13  |   93.66   | 83.22  |
|   Canopy   | 96.23 | 98.37 | 98.08 | 98.08  |   97.79   | 98.37  |
| Background | 85.57 | 96.61 | 92.22 | 92.22  |   88.21   | 96.61  |
|   Trunks   |  nan  |  nan  |  nan  |  nan   |    nan    |  nan   |
+------------+-------+-------+-------+--------+-----------+--------+
2023/06/12 21:32:01 - mmengine - INFO - Iter(val) [6/6]    aAcc: 93.5600  mIoU: 86.8600  mAcc: 92.7300  mDice: 92.8100  mFscore: 92.8100  mPrecision: 93.2200  mRecall: 92.7300  data_time: 0.1439  time: 0.5021
2023/06/12 21:32:39 - mmengine - INFO - Iter(train) [14050/20000]  lr: 1.9298e-05  eta: 1:05:54  time: 0.7578  data_time: 0.0125  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 100.0000
2023/06/12 21:33:19 - mmengine - INFO - Iter(train) [14100/20000]  lr: 1.9136e-05  eta: 1:05:23  time: 0.8422  data_time: 0.0131  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 99.9618
2023/06/12 21:33:57 - mmengine - INFO - Iter(train) [14150/20000]  lr: 1.8974e-05  eta: 1:04:52  time: 0.7441  data_time: 0.0136  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.3178
2023/06/12 21:34:36 - mmengine - INFO - Iter(train) [14200/20000]  lr: 1.8812e-05  eta: 1:04:21  time: 0.7969  data_time: 0.0087  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.7477
2023/06/12 21:35:13 - mmengine - INFO - Iter(train) [14250/20000]  lr: 1.8650e-05  eta: 1:03:49  time: 0.7279  data_time: 0.0156  memory: 12683  loss: 0.0016  decode.loss_ce: 0.0016  decode.acc_seg: 100.0000
2023/06/12 21:35:52 - mmengine - INFO - Iter(train) [14300/20000]  lr: 1.8487e-05  eta: 1:03:18  time: 0.8155  data_time: 0.0129  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 100.0000
2023/06/12 21:36:30 - mmengine - INFO - Iter(train) [14350/20000]  lr: 1.8325e-05  eta: 1:02:47  time: 0.8182  data_time: 0.0102  memory: 12683  loss: 0.0013  decode.loss_ce: 0.0013  decode.acc_seg: 99.7398
2023/06/12 21:37:06 - mmengine - INFO - Iter(train) [14400/20000]  lr: 1.8163e-05  eta: 1:02:15  time: 0.7523  data_time: 0.0107  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.9889
2023/06/12 21:37:43 - mmengine - INFO - Iter(train) [14450/20000]  lr: 1.8001e-05  eta: 1:01:43  time: 0.6764  data_time: 0.0085  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.9420
2023/06/12 21:38:20 - mmengine - INFO - Iter(train) [14500/20000]  lr: 1.7839e-05  eta: 1:01:11  time: 0.7639  data_time: 0.0090  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.9772
2023/06/12 21:38:57 - mmengine - INFO - Iter(train) [14550/20000]  lr: 1.7677e-05  eta: 1:00:39  time: 0.7574  data_time: 0.0095  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 100.0000
2023/06/12 21:39:34 - mmengine - INFO - Iter(train) [14600/20000]  lr: 1.7514e-05  eta: 1:00:07  time: 0.7962  data_time: 0.0089  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.6742
2023/06/12 21:40:11 - mmengine - INFO - Iter(train) [14650/20000]  lr: 1.7352e-05  eta: 0:59:34  time: 0.7414  data_time: 0.0088  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.9973
2023/06/12 21:40:48 - mmengine - INFO - Iter(train) [14700/20000]  lr: 1.7190e-05  eta: 0:59:02  time: 0.7608  data_time: 0.0088  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 95.7202
2023/06/12 21:41:24 - mmengine - INFO - Iter(train) [14750/20000]  lr: 1.7028e-05  eta: 0:58:30  time: 0.7917  data_time: 0.0087  memory: 12683  loss: 0.0020  decode.loss_ce: 0.0020  decode.acc_seg: 99.3809
2023/06/12 21:42:01 - mmengine - INFO - Iter(train) [14800/20000]  lr: 1.6866e-05  eta: 0:57:58  time: 0.8069  data_time: 0.0104  memory: 12683  loss: 0.0015  decode.loss_ce: 0.0015  decode.acc_seg: 99.0695
2023/06/12 21:42:38 - mmengine - INFO - Iter(train) [14850/20000]  lr: 1.6704e-05  eta: 0:57:26  time: 0.7855  data_time: 0.0092  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.7499
2023/06/12 21:43:16 - mmengine - INFO - Iter(train) [14900/20000]  lr: 1.6541e-05  eta: 0:56:53  time: 0.7553  data_time: 0.0100  memory: 12683  loss: 0.0025  decode.loss_ce: 0.0025  decode.acc_seg: 97.7544
2023/06/12 21:43:53 - mmengine - INFO - Iter(train) [14950/20000]  lr: 1.6379e-05  eta: 0:56:21  time: 0.7917  data_time: 0.0090  memory: 12683  loss: 0.0010  decode.loss_ce: 0.0010  decode.acc_seg: 99.8706
2023/06/12 21:44:29 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 21:44:29 - mmengine - INFO - Iter(train) [15000/20000]  lr: 1.6217e-05  eta: 0:55:49  time: 0.7959  data_time: 0.0125  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.8079
2023/06/12 21:45:07 - mmengine - INFO - Iter(train) [15050/20000]  lr: 1.6055e-05  eta: 0:55:17  time: 0.7636  data_time: 0.0108  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 100.0000
2023/06/12 21:45:43 - mmengine - INFO - Iter(train) [15100/20000]  lr: 1.5893e-05  eta: 0:54:44  time: 0.7886  data_time: 0.0116  memory: 12683  loss: 0.0012  decode.loss_ce: 0.0012  decode.acc_seg: 99.8637
2023/06/12 21:46:21 - mmengine - INFO - Iter(train) [15150/20000]  lr: 1.5731e-05  eta: 0:54:12  time: 0.7966  data_time: 0.0109  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000
2023/06/12 21:46:57 - mmengine - INFO - Iter(train) [15200/20000]  lr: 1.5568e-05  eta: 0:53:39  time: 0.7662  data_time: 0.0085  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.2848
2023/06/12 21:47:33 - mmengine - INFO - Iter(train) [15250/20000]  lr: 1.5406e-05  eta: 0:53:06  time: 0.6960  data_time: 0.0088  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.8172
2023/06/12 21:48:10 - mmengine - INFO - Iter(train) [15300/20000]  lr: 1.5244e-05  eta: 0:52:34  time: 0.6955  data_time: 0.0136  memory: 12683  loss: 0.0013  decode.loss_ce: 0.0013  decode.acc_seg: 100.0000
2023/06/12 21:48:48 - mmengine - INFO - Iter(train) [15350/20000]  lr: 1.5082e-05  eta: 0:52:02  time: 0.7204  data_time: 0.0133  memory: 12683  loss: 0.0023  decode.loss_ce: 0.0023  decode.acc_seg: 99.2518
2023/06/12 21:49:26 - mmengine - INFO - Iter(train) [15400/20000]  lr: 1.4920e-05  eta: 0:51:29  time: 0.7638  data_time: 0.0120  memory: 12683  loss: 0.0010  decode.loss_ce: 0.0010  decode.acc_seg: 99.9589
2023/06/12 21:50:03 - mmengine - INFO - Iter(train) [15450/20000]  lr: 1.4758e-05  eta: 0:50:57  time: 0.7464  data_time: 0.0121  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.9405
2023/06/12 21:50:40 - mmengine - INFO - Iter(train) [15500/20000]  lr: 1.4595e-05  eta: 0:50:24  time: 0.7179  data_time: 0.0126  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 99.8733
2023/06/12 21:51:17 - mmengine - INFO - Iter(train) [15550/20000]  lr: 1.4433e-05  eta: 0:49:52  time: 0.6967  data_time: 0.0129  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.9760
2023/06/12 21:51:54 - mmengine - INFO - Iter(train) [15600/20000]  lr: 1.4271e-05  eta: 0:49:19  time: 0.7080  data_time: 0.0137  memory: 12683  loss: 0.0011  decode.loss_ce: 0.0011  decode.acc_seg: 100.0000
2023/06/12 21:52:31 - mmengine - INFO - Iter(train) [15650/20000]  lr: 1.4109e-05  eta: 0:48:46  time: 0.6819  data_time: 0.0126  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.6904
2023/06/12 21:53:09 - mmengine - INFO - Iter(train) [15700/20000]  lr: 1.3947e-05  eta: 0:48:14  time: 0.7094  data_time: 0.0119  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.8387
2023/06/12 21:53:46 - mmengine - INFO - Iter(train) [15750/20000]  lr: 1.3785e-05  eta: 0:47:41  time: 0.6873  data_time: 0.0134  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 99.8783
2023/06/12 21:54:24 - mmengine - INFO - Iter(train) [15800/20000]  lr: 1.3622e-05  eta: 0:47:08  time: 0.7476  data_time: 0.0140  memory: 12683  loss: 0.0039  decode.loss_ce: 0.0039  decode.acc_seg: 99.4418
2023/06/12 21:55:02 - mmengine - INFO - Iter(train) [15850/20000]  lr: 1.3460e-05  eta: 0:46:36  time: 0.8109  data_time: 0.0128  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.9269
2023/06/12 21:55:40 - mmengine - INFO - Iter(train) [15900/20000]  lr: 1.3298e-05  eta: 0:46:03  time: 0.7834  data_time: 0.0116  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000
2023/06/12 21:56:17 - mmengine - INFO - Iter(train) [15950/20000]  lr: 1.3136e-05  eta: 0:45:31  time: 0.7471  data_time: 0.0123  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.9966
2023/06/12 21:56:55 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 21:56:55 - mmengine - INFO - Iter(train) [16000/20000]  lr: 1.2974e-05  eta: 0:44:58  time: 0.7180  data_time: 0.0125  memory: 12683  loss: 0.0018  decode.loss_ce: 0.0018  decode.acc_seg: 99.9986
2023/06/12 21:56:55 - mmengine - INFO - Saving checkpoint at 16000 iterations
2023/06/12 21:57:00 - mmengine - INFO - per class results:
2023/06/12 21:57:00 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
|    Fuel    | 77.47 | 82.05 |  87.3 |  87.3  |   93.27   | 82.05  |
|   Canopy   | 95.96 | 98.64 | 97.94 | 97.94  |   97.25   | 98.64  |
| Background | 84.81 |  96.0 | 91.78 | 91.78  |   87.92   |  96.0  |
|   Trunks   |  nan  |  nan  |  nan  |  nan   |    nan    |  nan   |
+------------+-------+-------+-------+--------+-----------+--------+
2023/06/12 21:57:00 - mmengine - INFO - Iter(val) [6/6]    aAcc: 93.1600  mIoU: 86.0800  mAcc: 92.2300  mDice: 92.3400  mFscore: 92.3400  mPrecision: 92.8100  mRecall: 92.2300  data_time: 0.1348  time: 0.3758
2023/06/12 21:57:38 - mmengine - INFO - Iter(train) [16050/20000]  lr: 1.2812e-05  eta: 0:44:25  time: 0.7564  data_time: 0.0132  memory: 12683  loss: 0.0012  decode.loss_ce: 0.0012  decode.acc_seg: 99.8745
2023/06/12 21:58:16 - mmengine - INFO - Iter(train) [16100/20000]  lr: 1.2649e-05  eta: 0:43:52  time: 0.8129  data_time: 0.0126  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.8405
2023/06/12 21:58:54 - mmengine - INFO - Iter(train) [16150/20000]  lr: 1.2487e-05  eta: 0:43:20  time: 0.7911  data_time: 0.0124  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 100.0000
2023/06/12 21:59:31 - mmengine - INFO - Iter(train) [16200/20000]  lr: 1.2325e-05  eta: 0:42:47  time: 0.7668  data_time: 0.0118  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.9984
2023/06/12 22:00:08 - mmengine - INFO - Iter(train) [16250/20000]  lr: 1.2163e-05  eta: 0:42:14  time: 0.6839  data_time: 0.0121  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.4677
2023/06/12 22:00:46 - mmengine - INFO - Iter(train) [16300/20000]  lr: 1.2001e-05  eta: 0:41:41  time: 0.7996  data_time: 0.0100  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 99.9611
2023/06/12 22:01:24 - mmengine - INFO - Iter(train) [16350/20000]  lr: 1.1838e-05  eta: 0:41:08  time: 0.7301  data_time: 0.0108  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 99.9809
2023/06/12 22:02:02 - mmengine - INFO - Iter(train) [16400/20000]  lr: 1.1676e-05  eta: 0:40:35  time: 0.7647  data_time: 0.0132  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 100.0000
2023/06/12 22:02:40 - mmengine - INFO - Iter(train) [16450/20000]  lr: 1.1514e-05  eta: 0:40:02  time: 0.7801  data_time: 0.0126  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 100.0000
2023/06/12 22:03:17 - mmengine - INFO - Iter(train) [16500/20000]  lr: 1.1352e-05  eta: 0:39:29  time: 0.7021  data_time: 0.0101  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.9528
2023/06/12 22:03:55 - mmengine - INFO - Iter(train) [16550/20000]  lr: 1.1190e-05  eta: 0:38:56  time: 0.7692  data_time: 0.0140  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.9135
2023/06/12 22:04:33 - mmengine - INFO - Iter(train) [16600/20000]  lr: 1.1028e-05  eta: 0:38:23  time: 0.8137  data_time: 0.0145  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.9050
2023/06/12 22:05:11 - mmengine - INFO - Iter(train) [16650/20000]  lr: 1.0865e-05  eta: 0:37:50  time: 0.7313  data_time: 0.0132  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 100.0000
2023/06/12 22:05:48 - mmengine - INFO - Iter(train) [16700/20000]  lr: 1.0703e-05  eta: 0:37:17  time: 0.7106  data_time: 0.0133  memory: 12683  loss: 0.0001  decode.loss_ce: 0.0001  decode.acc_seg: 100.0000
2023/06/12 22:06:25 - mmengine - INFO - Iter(train) [16750/20000]  lr: 1.0541e-05  eta: 0:36:43  time: 0.7056  data_time: 0.0127  memory: 12683  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000
2023/06/12 22:07:03 - mmengine - INFO - Iter(train) [16800/20000]  lr: 1.0379e-05  eta: 0:36:10  time: 0.6930  data_time: 0.0122  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.5128
2023/06/12 22:07:40 - mmengine - INFO - Iter(train) [16850/20000]  lr: 1.0217e-05  eta: 0:35:37  time: 0.6992  data_time: 0.0122  memory: 12683  loss: 0.0010  decode.loss_ce: 0.0010  decode.acc_seg: 100.0000
2023/06/12 22:08:17 - mmengine - INFO - Iter(train) [16900/20000]  lr: 1.0055e-05  eta: 0:35:03  time: 0.7175  data_time: 0.0122  memory: 12683  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 99.9570
2023/06/12 22:08:55 - mmengine - INFO - Iter(train) [16950/20000]  lr: 9.8924e-06  eta: 0:34:30  time: 0.7396  data_time: 0.0134  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.7231
2023/06/12 22:09:33 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 22:09:33 - mmengine - INFO - Iter(train) [17000/20000]  lr: 9.7303e-06  eta: 0:33:57  time: 0.7938  data_time: 0.0158  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.9395
2023/06/12 22:10:11 - mmengine - INFO - Iter(train) [17050/20000]  lr: 9.5681e-06  eta: 0:33:24  time: 0.7103  data_time: 0.0132  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 100.0000
2023/06/12 22:10:48 - mmengine - INFO - Iter(train) [17100/20000]  lr: 9.4059e-06  eta: 0:32:50  time: 0.6922  data_time: 0.0129  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 100.0000
2023/06/12 22:11:26 - mmengine - INFO - Iter(train) [17150/20000]  lr: 9.2437e-06  eta: 0:32:17  time: 0.7721  data_time: 0.0132  memory: 12683  loss: 0.0025  decode.loss_ce: 0.0025  decode.acc_seg: 99.9696
2023/06/12 22:12:04 - mmengine - INFO - Iter(train) [17200/20000]  lr: 9.0816e-06  eta: 0:31:44  time: 0.8016  data_time: 0.0138  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.9587
2023/06/12 22:12:42 - mmengine - INFO - Iter(train) [17250/20000]  lr: 8.9194e-06  eta: 0:31:10  time: 0.7541  data_time: 0.0155  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 99.9931
2023/06/12 22:13:21 - mmengine - INFO - Iter(train) [17300/20000]  lr: 8.7572e-06  eta: 0:30:37  time: 0.8112  data_time: 0.0128  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 100.0000
2023/06/12 22:13:58 - mmengine - INFO - Iter(train) [17350/20000]  lr: 8.5951e-06  eta: 0:30:04  time: 0.7258  data_time: 0.0133  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.9834
2023/06/12 22:14:37 - mmengine - INFO - Iter(train) [17400/20000]  lr: 8.4329e-06  eta: 0:29:30  time: 0.7730  data_time: 0.0132  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.9279
2023/06/12 22:15:15 - mmengine - INFO - Iter(train) [17450/20000]  lr: 8.2707e-06  eta: 0:28:57  time: 0.7669  data_time: 0.0136  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000
2023/06/12 22:15:53 - mmengine - INFO - Iter(train) [17500/20000]  lr: 8.1085e-06  eta: 0:28:23  time: 0.7778  data_time: 0.0137  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 100.0000
2023/06/12 22:16:32 - mmengine - INFO - Iter(train) [17550/20000]  lr: 7.9464e-06  eta: 0:27:50  time: 0.7618  data_time: 0.0142  memory: 12683  loss: 0.0008  decode.loss_ce: 0.0008  decode.acc_seg: 100.0000
2023/06/12 22:17:09 - mmengine - INFO - Iter(train) [17600/20000]  lr: 7.7842e-06  eta: 0:27:16  time: 0.6900  data_time: 0.0125  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.6601
2023/06/12 22:17:46 - mmengine - INFO - Iter(train) [17650/20000]  lr: 7.6220e-06  eta: 0:26:42  time: 0.7014  data_time: 0.0127  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 99.2983
2023/06/12 22:18:25 - mmengine - INFO - Iter(train) [17700/20000]  lr: 7.4599e-06  eta: 0:26:09  time: 0.7570  data_time: 0.0138  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.9706
2023/06/12 22:18:59 - mmengine - INFO - Iter(train) [17750/20000]  lr: 7.2977e-06  eta: 0:25:35  time: 0.4727  data_time: 0.0129  memory: 12683  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 99.8220
2023/06/12 22:19:23 - mmengine - INFO - Iter(train) [17800/20000]  lr: 7.1355e-06  eta: 0:24:59  time: 0.4707  data_time: 0.0124  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.9037
2023/06/12 22:19:46 - mmengine - INFO - Iter(train) [17850/20000]  lr: 6.9733e-06  eta: 0:24:24  time: 0.4705  data_time: 0.0125  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.4917
2023/06/12 22:20:10 - mmengine - INFO - Iter(train) [17900/20000]  lr: 6.8112e-06  eta: 0:23:49  time: 0.4702  data_time: 0.0121  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.7207
2023/06/12 22:20:33 - mmengine - INFO - Iter(train) [17950/20000]  lr: 6.6490e-06  eta: 0:23:13  time: 0.4612  data_time: 0.0099  memory: 12683  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 99.9549
2023/06/12 22:20:56 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 22:20:56 - mmengine - INFO - Iter(train) [18000/20000]  lr: 6.4868e-06  eta: 0:22:38  time: 0.4640  data_time: 0.0099  memory: 12683  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000
2023/06/12 22:20:56 - mmengine - INFO - Saving checkpoint at 18000 iterations
2023/06/12 22:21:02 - mmengine - INFO - per class results:
2023/06/12 22:21:02 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
|    Fuel    | 81.38 | 86.32 | 89.73 | 89.73  |   93.42   | 86.32  |
|   Canopy   | 95.98 | 98.59 | 97.95 | 97.95  |   97.31   | 98.59  |
| Background | 87.92 | 96.03 | 93.57 | 93.57  |   91.24   | 96.03  |
|   Trunks   |  0.0  |  nan  |  0.0  |  nan   |    0.0    |  nan   |
+------------+-------+-------+-------+--------+-----------+--------+
2023/06/12 22:21:02 - mmengine - INFO - Iter(val) [6/6]    aAcc: 94.3500  mIoU: 66.3200  mAcc: 93.6500  mDice: 70.3100  mFscore: 93.7500  mPrecision: 70.4900  mRecall: 93.6500  data_time: 0.1376  time: 0.3246
2023/06/12 22:21:25 - mmengine - INFO - Iter(train) [18050/20000]  lr: 6.3247e-06  eta: 0:22:03  time: 0.4602  data_time: 0.0094  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 99.9955
2023/06/12 22:21:48 - mmengine - INFO - Iter(train) [18100/20000]  lr: 6.1625e-06  eta: 0:21:28  time: 0.4663  data_time: 0.0106  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.7991
2023/06/12 22:22:12 - mmengine - INFO - Iter(train) [18150/20000]  lr: 6.0003e-06  eta: 0:20:53  time: 0.4741  data_time: 0.0126  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.7810
2023/06/12 22:22:36 - mmengine - INFO - Iter(train) [18200/20000]  lr: 5.8382e-06  eta: 0:20:18  time: 0.4702  data_time: 0.0126  memory: 12683  loss: 0.0011  decode.loss_ce: 0.0011  decode.acc_seg: 99.8963
2023/06/12 22:22:59 - mmengine - INFO - Iter(train) [18250/20000]  lr: 5.6760e-06  eta: 0:19:43  time: 0.4692  data_time: 0.0123  memory: 12683  loss: 0.0018  decode.loss_ce: 0.0018  decode.acc_seg: 100.0000
2023/06/12 22:23:23 - mmengine - INFO - Iter(train) [18300/20000]  lr: 5.5138e-06  eta: 0:19:09  time: 0.4702  data_time: 0.0123  memory: 12683  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000
2023/06/12 22:23:46 - mmengine - INFO - Iter(train) [18350/20000]  lr: 5.3516e-06  eta: 0:18:34  time: 0.4696  data_time: 0.0121  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.7254
2023/06/12 22:24:10 - mmengine - INFO - Iter(train) [18400/20000]  lr: 5.1895e-06  eta: 0:17:59  time: 0.4731  data_time: 0.0128  memory: 12683  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 99.9564
2023/06/12 22:24:33 - mmengine - INFO - Iter(train) [18450/20000]  lr: 5.0273e-06  eta: 0:17:25  time: 0.4694  data_time: 0.0122  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.6002
2023/06/12 22:24:57 - mmengine - INFO - Iter(train) [18500/20000]  lr: 4.8651e-06  eta: 0:16:50  time: 0.4691  data_time: 0.0121  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.9302
2023/06/12 22:25:20 - mmengine - INFO - Iter(train) [18550/20000]  lr: 4.7030e-06  eta: 0:16:16  time: 0.4698  data_time: 0.0123  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.6998
2023/06/12 22:25:44 - mmengine - INFO - Iter(train) [18600/20000]  lr: 4.5408e-06  eta: 0:15:41  time: 0.4692  data_time: 0.0122  memory: 12683  loss: 0.0001  decode.loss_ce: 0.0001  decode.acc_seg: 100.0000
2023/06/12 22:26:07 - mmengine - INFO - Iter(train) [18650/20000]  lr: 4.3786e-06  eta: 0:15:07  time: 0.4788  data_time: 0.0125  memory: 12683  loss: 0.0011  decode.loss_ce: 0.0011  decode.acc_seg: 99.8989
2023/06/12 22:26:31 - mmengine - INFO - Iter(train) [18700/20000]  lr: 4.2164e-06  eta: 0:14:33  time: 0.4697  data_time: 0.0123  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.9683
2023/06/12 22:26:55 - mmengine - INFO - Iter(train) [18750/20000]  lr: 4.0543e-06  eta: 0:13:58  time: 0.4692  data_time: 0.0121  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.9803
2023/06/12 22:27:18 - mmengine - INFO - Iter(train) [18800/20000]  lr: 3.8921e-06  eta: 0:13:24  time: 0.4708  data_time: 0.0123  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 99.7173
2023/06/12 22:27:42 - mmengine - INFO - Iter(train) [18850/20000]  lr: 3.7299e-06  eta: 0:12:50  time: 0.4709  data_time: 0.0123  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 100.0000
2023/06/12 22:28:05 - mmengine - INFO - Iter(train) [18900/20000]  lr: 3.5678e-06  eta: 0:12:16  time: 0.4706  data_time: 0.0122  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000
2023/06/12 22:28:29 - mmengine - INFO - Iter(train) [18950/20000]  lr: 3.4056e-06  eta: 0:11:42  time: 0.4707  data_time: 0.0123  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.9881
2023/06/12 22:28:52 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 22:28:52 - mmengine - INFO - Iter(train) [19000/20000]  lr: 3.2434e-06  eta: 0:11:08  time: 0.4706  data_time: 0.0123  memory: 12683  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 99.9118
2023/06/12 22:29:16 - mmengine - INFO - Iter(train) [19050/20000]  lr: 3.0812e-06  eta: 0:10:34  time: 0.4707  data_time: 0.0121  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 100.0000
2023/06/12 22:29:39 - mmengine - INFO - Iter(train) [19100/20000]  lr: 2.9191e-06  eta: 0:10:00  time: 0.4714  data_time: 0.0123  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.8059
2023/06/12 22:30:03 - mmengine - INFO - Iter(train) [19150/20000]  lr: 2.7569e-06  eta: 0:09:26  time: 0.4712  data_time: 0.0123  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.8834
2023/06/12 22:30:27 - mmengine - INFO - Iter(train) [19200/20000]  lr: 2.5947e-06  eta: 0:08:53  time: 0.4710  data_time: 0.0124  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.9989
2023/06/12 22:30:50 - mmengine - INFO - Iter(train) [19250/20000]  lr: 2.4326e-06  eta: 0:08:19  time: 0.4705  data_time: 0.0123  memory: 12683  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 99.9981
2023/06/12 22:31:14 - mmengine - INFO - Iter(train) [19300/20000]  lr: 2.2704e-06  eta: 0:07:45  time: 0.4725  data_time: 0.0126  memory: 12683  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 99.8065
2023/06/12 22:31:38 - mmengine - INFO - Iter(train) [19350/20000]  lr: 2.1082e-06  eta: 0:07:12  time: 0.4705  data_time: 0.0123  memory: 12683  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 99.5461
2023/06/12 22:32:01 - mmengine - INFO - Iter(train) [19400/20000]  lr: 1.9461e-06  eta: 0:06:38  time: 0.4705  data_time: 0.0122  memory: 12683  loss: 0.0007  decode.loss_ce: 0.0007  decode.acc_seg: 99.8944
2023/06/12 22:32:25 - mmengine - INFO - Iter(train) [19450/20000]  lr: 1.7839e-06  eta: 0:06:05  time: 0.4701  data_time: 0.0121  memory: 12683  loss: 0.0001  decode.loss_ce: 0.0001  decode.acc_seg: 99.9500
2023/06/12 22:32:48 - mmengine - INFO - Iter(train) [19500/20000]  lr: 1.6217e-06  eta: 0:05:31  time: 0.4704  data_time: 0.0121  memory: 12683  loss: 0.0001  decode.loss_ce: 0.0001  decode.acc_seg: 100.0000
2023/06/12 22:33:12 - mmengine - INFO - Iter(train) [19550/20000]  lr: 1.4595e-06  eta: 0:04:58  time: 0.4728  data_time: 0.0127  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000
2023/06/12 22:33:35 - mmengine - INFO - Iter(train) [19600/20000]  lr: 1.2974e-06  eta: 0:04:24  time: 0.4646  data_time: 0.0102  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.8810
2023/06/12 22:33:58 - mmengine - INFO - Iter(train) [19650/20000]  lr: 1.1352e-06  eta: 0:03:51  time: 0.4611  data_time: 0.0095  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.9320
2023/06/12 22:34:21 - mmengine - INFO - Iter(train) [19700/20000]  lr: 9.7303e-07  eta: 0:03:18  time: 0.4616  data_time: 0.0096  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000
2023/06/12 22:34:45 - mmengine - INFO - Iter(train) [19750/20000]  lr: 8.1085e-07  eta: 0:02:45  time: 0.4610  data_time: 0.0095  memory: 12683  loss: 0.0012  decode.loss_ce: 0.0012  decode.acc_seg: 99.7239
2023/06/12 22:35:08 - mmengine - INFO - Iter(train) [19800/20000]  lr: 6.4868e-07  eta: 0:02:12  time: 0.4810  data_time: 0.0127  memory: 12683  loss: 0.0005  decode.loss_ce: 0.0005  decode.acc_seg: 99.9726
2023/06/12 22:35:31 - mmengine - INFO - Iter(train) [19850/20000]  lr: 4.8651e-07  eta: 0:01:38  time: 0.4613  data_time: 0.0095  memory: 12683  loss: 0.0012  decode.loss_ce: 0.0012  decode.acc_seg: 100.0000
2023/06/12 22:35:55 - mmengine - INFO - Iter(train) [19900/20000]  lr: 3.2434e-07  eta: 0:01:05  time: 0.4734  data_time: 0.0135  memory: 12683  loss: 0.0044  decode.loss_ce: 0.0044  decode.acc_seg: 99.8916
2023/06/12 22:36:18 - mmengine - INFO - Iter(train) [19950/20000]  lr: 1.6217e-07  eta: 0:00:32  time: 0.4712  data_time: 0.0124  memory: 12683  loss: 0.0006  decode.loss_ce: 0.0006  decode.acc_seg: 99.8926
2023/06/12 22:36:42 - mmengine - INFO - Exp name: segformer_mit-b5_8xb1-20k_safeforest_gascola_23_04_27_collect_04_compressed-1024x1024_20230612_185545
2023/06/12 22:36:42 - mmengine - INFO - Iter(train) [20000/20000]  lr: 0.0000e+00  eta: 0:00:00  time: 0.4716  data_time: 0.0124  memory: 12683  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 99.9609
2023/06/12 22:36:42 - mmengine - INFO - Saving checkpoint at 20000 iterations
2023/06/12 22:36:48 - mmengine - INFO - per class results:
2023/06/12 22:36:48 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
|    Fuel    | 81.24 | 86.02 | 89.65 | 89.65  |    93.6   | 86.02  |
|   Canopy   |  95.9 | 98.55 |  97.9 |  97.9  |   97.27   | 98.55  |
| Background | 87.97 | 96.27 |  93.6 |  93.6  |   91.08   | 96.27  |
|   Trunks   |  0.0  |  nan  |  0.0  |  nan   |    0.0    |  nan   |
+------------+-------+-------+-------+--------+-----------+--------+
2023/06/12 22:36:48 - mmengine - INFO - Iter(val) [6/6]    aAcc: 94.3200  mIoU: 66.2800  mAcc: 93.6100  mDice: 70.2900  mFscore: 93.7200  mPrecision: 70.4900  mRecall: 93.6100  data_time: 0.1362  time: 0.3239
